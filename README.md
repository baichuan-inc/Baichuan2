<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->

<div align="center">
<h1>
  Baichuan 2
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/baichuan-inc/" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://modelscope.cn/organization/baichuan-inc" target="_blank">ModelScope</a> â€¢ ğŸ’¬ <a href="https://github.com/baichuan-inc/Baichuan-7B/blob/main/media/wechat.jpeg?raw=true" target="_blank">WeChat</a>
</p>

<div align="center">

ğŸš€ [ç™¾å·53Bå¤§æ¨¡å‹åœ¨çº¿å¯¹è¯å¹³å°](https://www.baichuan-ai.com/)å·²æ­£å¼å‘å…¬ä¼—å¼€æ”¾ ğŸ‰

[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/baichuan-inc/Baichuan2/blob/main/LICENSE)


<h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> |
        <a href="https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md">English</a>
    <p>
</h4>

</div>

# ç›®å½•

- [ğŸ“– æ¨¡å‹ä»‹ç»](#æ¨¡å‹ä»‹ç»)
- [ğŸ“Š Benchmark ç»“æœ ğŸ¥‡ğŸ¥‡ğŸ”¥ğŸ”¥](#Benchmark-ç»“æœ)
- [âš™ï¸ æ¨ç†å’Œéƒ¨ç½²](#æ¨ç†å’Œéƒ¨ç½²)
- [ğŸ› ï¸ æ¨¡å‹å¾®è°ƒ](#æ¨¡å‹å¾®è°ƒ)
- [ğŸ’¾ ä¸­é—´ Checkpoints ğŸ”¥ğŸ”¥](#ä¸­é—´-Checkpoints)
- [ğŸ‘¥ ç¤¾åŒºä¸ç”Ÿæ€](#ç¤¾åŒºä¸ç”Ÿæ€)
- [ğŸ“œ å£°æ˜ã€åè®®ã€å¼•ç”¨](#å£°æ˜åè®®å¼•ç”¨)

# æ¨¡å‹ä»‹ç»

- Baichuan 2 æ˜¯ç™¾å·æ™ºèƒ½æ¨å‡ºçš„**æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹**ï¼Œé‡‡ç”¨ **2.6 ä¸‡äº¿**  Tokens çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒã€‚
- Baichuan 2 åœ¨å¤šä¸ªæƒå¨çš„ä¸­æ–‡ã€è‹±æ–‡å’Œå¤šè¯­è¨€çš„é€šç”¨ã€é¢†åŸŸ benchmark ä¸Šå–å¾—åŒå°ºå¯¸**æœ€ä½³**çš„æ•ˆæœã€‚
- æœ¬æ¬¡å‘å¸ƒåŒ…å«æœ‰ **7B**ã€**13B** çš„ **Base** å’Œ **Chat** ç‰ˆæœ¬ï¼Œå¹¶æä¾›äº† Chat ç‰ˆæœ¬çš„ **4bits é‡åŒ–**ã€‚
- æ‰€æœ‰ç‰ˆæœ¬å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ã€‚åŒæ—¶ï¼Œå¼€å‘è€…é€šè¿‡é‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹å•†ç”¨è®¸å¯åï¼Œå³å¯**å…è´¹å•†ç”¨**ï¼Œè¯·å‚è€ƒ[åè®®](#åè®®)ç« èŠ‚ã€‚
- æ¬¢è¿é˜…è¯»æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Š [Baichuan 2: Open Large-scale Language Models](https://arxiv.org/abs/2309.10305) è·å–æ›´å¤šä¿¡æ¯ã€‚

æœ¬æ¬¡å‘å¸ƒç‰ˆæœ¬å’Œä¸‹è½½é“¾æ¥è§ä¸‹è¡¨ï¼š
|         | åŸºåº§æ¨¡å‹  | å¯¹é½æ¨¡å‹ | å¯¹é½æ¨¡å‹ 4bits é‡åŒ– |
|:-------:|:-------:|:-------:|:-----------------:|
| 7B      | ğŸ¤— [Baichuan2-7B-Base](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base) | ğŸ¤— [Baichuan2-7B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat) | ğŸ¤— [Baichuan2-7B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-4bits) |
| 13B     | ğŸ¤— [Baichuan2-13B-Base](https://huggingface.co/baichuan-inc/Baichuan2-13B-Base) | ğŸ¤— [Baichuan2-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat) | ğŸ¤— [Baichuan2-13B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits) |

# Benchmark ç»“æœ

æˆ‘ä»¬åœ¨[é€šç”¨](#é€šç”¨é¢†åŸŸ)ã€[æ³•å¾‹](#æ³•å¾‹åŒ»ç–—)ã€[åŒ»ç–—](#æ³•å¾‹åŒ»ç–—)ã€[æ•°å­¦](#æ•°å­¦ä»£ç )ã€[ä»£ç ](#æ•°å­¦ä»£ç )å’Œ[å¤šè¯­è¨€ç¿»è¯‘](#å¤šè¯­è¨€ç¿»è¯‘)å…­ä¸ªé¢†åŸŸçš„ä¸­è‹±æ–‡å’Œå¤šè¯­è¨€æƒå¨æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ã€‚

## é€šç”¨é¢†åŸŸ

åœ¨é€šç”¨é¢†åŸŸæˆ‘ä»¬åœ¨ä»¥ä¸‹æ•°æ®é›†ä¸Šè¿›è¡Œäº† 5-shot æµ‹è¯•ã€‚
- [C-Eval](https://cevalbenchmark.com/index.html#home) æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº† 52 ä¸ªå­¦ç§‘å’Œå››ä¸ªéš¾åº¦çš„çº§åˆ«ã€‚æˆ‘ä»¬ä½¿ç”¨è¯¥æ•°æ®é›†çš„ dev é›†ä½œä¸º few-shot çš„æ¥æºï¼Œåœ¨ test é›†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚æˆ‘ä»¬é‡‡ç”¨äº† [Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B/tree/main) çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- [MMLU](https://arxiv.org/abs/2009.03300) æ˜¯åŒ…å« 57 ä¸ªä»»åŠ¡çš„è‹±æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†åˆç­‰æ•°å­¦ã€ç¾å›½å†å²ã€è®¡ç®—æœºç§‘å­¦ã€æ³•å¾‹ç­‰ï¼Œéš¾åº¦è¦†ç›–é«˜ä¸­æ°´å¹³åˆ°ä¸“å®¶æ°´å¹³ï¼Œæ˜¯ç›®å‰ä¸»æµçš„ LLM è¯„æµ‹æ•°æ®é›†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†[å¼€æº](https://github.com/hendrycks/test)çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- [CMMLU](https://github.com/haonan-li/CMMLU) æ˜¯ä¸€ä¸ªåŒ…å« 67 ä¸ªä¸»é¢˜çš„ç»¼åˆæ€§æ€§ä¸­æ–‡è¯„ä¼°åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬é‡‡ç”¨äº†å…¶[å®˜æ–¹](https://github.com/haonan-li/CMMLU)çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- [Gaokao](https://github.com/OpenLMLab/GAOKAO-Bench) æ˜¯ä¸€ä¸ªä»¥ä¸­å›½é«˜è€ƒé¢˜ä½œä¸ºè¯„æµ‹å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ•°æ®é›†ï¼Œç”¨ä»¥è¯„ä¼°æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶è¿›è¡Œäº†éšæœºåˆ’åˆ†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- [AGIEval](https://github.com/microsoft/AGIEval) æ—¨åœ¨è¯„ä¼°æ¨¡å‹çš„è®¤çŸ¥å’Œè§£å†³é—®é¢˜ç›¸å…³çš„ä»»åŠ¡ä¸­çš„ä¸€èˆ¬èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å››é€‰ä¸€å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶è¿›è¡Œäº†éšæœºåˆ’åˆ†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- [BBH](https://huggingface.co/datasets/lukaemon/bbh) æ˜¯ä¸€ä¸ªæŒ‘æˆ˜æ€§ä»»åŠ¡ Big-Bench çš„å­é›†ã€‚Big-Bench ç›®å‰åŒ…æ‹¬ 204 é¡¹ä»»åŠ¡ã€‚ä»»åŠ¡ä¸»é¢˜æ¶‰åŠè¯­è¨€å­¦ã€å„¿ç«¥å‘å±•ã€æ•°å­¦ã€å¸¸è¯†æ¨ç†ã€ç”Ÿç‰©å­¦ã€ç‰©ç†å­¦ã€ç¤¾ä¼šåè§ã€è½¯ä»¶å¼€å‘ç­‰æ–¹é¢ã€‚BBH æ˜¯ä» 204 é¡¹ Big-Bench è¯„æµ‹åŸºå‡†ä»»åŠ¡ä¸­å¤§æ¨¡å‹è¡¨ç°ä¸å¥½çš„ä»»åŠ¡å•ç‹¬æ‹¿å‡ºæ¥å½¢æˆçš„è¯„æµ‹åŸºå‡†ã€‚

### 7B æ¨¡å‹ç»“æœ

|                       | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:---------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|                       |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
| **GPT-4**             | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | 75.12   |
| **GPT-3.5 Turbo**     | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | 61.59   |
| **LLaMA-7B**          | 27.10      | 35.10    | 26.75     | 27.81      | 28.17       | 32.38   |
| **LLaMA2-7B**         | 28.90      | 45.73    | 31.38     | 25.97      | 26.53       | 39.16   |
| **MPT-7B**            | 27.15      | 27.93    | 26.00     | 26.54      | 24.83       | 35.20   |
| **Falcon-7B**         | 24.23      | 26.03    | 25.66     | 24.24      | 24.10       | 28.77   |
| **ChatGLM2-6B**       | 50.20      | 45.90    | 49.00     | 49.44      | 45.28       | 31.65   |
| **Baichuan-7B**       | 42.80      | 42.30    | 44.02     | 36.34      | 34.44       | 32.48   |
| **Baichuan2-7B-Base** | 54.00      | 54.16    | 57.07     | 47.47      | 42.73       | 41.56   |

### 13B æ¨¡å‹ç»“æœ

|                             | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:---------------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|                             |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
| **GPT-4**                   | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | 75.12   |
| **GPT-3.5 Turbo**           | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | 61.59   |
| **LLaMA-13B**               | 28.50      | 46.30    | 31.15     | 28.23      | 28.22       | 37.89   |
| **LLaMA2-13B**              | 35.80      | 55.09    | 37.99     | 30.83      | 32.29       | 46.98   |
| **Vicuna-13B**              | 32.80      | 52.00    | 36.28     | 30.11      | 31.55       | 43.04   |
| **Chinese-Alpaca-Plus-13B** | 38.80      | 43.90    | 33.43     | 34.78      | 35.46       | 28.94   |
| **XVERSE-13B**              | 53.70      | 55.21    | 58.44     | 44.69      | 42.54       | 38.06   |
| **Baichuan-13B-Base**       | 52.40      | 51.60    | 55.30     | 49.69      | 43.20       | 43.01   |
| **Baichuan2-13B-Base**      | 58.10      | 59.17    | 61.97     | 54.33      | 48.17       | 48.78   |

## æ³•å¾‹ã€åŒ»ç–—

æ³•å¾‹é¢†åŸŸæˆ‘ä»¬ä½¿ç”¨äº† [JEC-QA](https://jecqa.thunlp.org/) æ•°æ®é›†ã€‚JEC-QA æ•°æ®é›†æ¥æºäºä¸­å›½å›½å®¶å¸æ³•è€ƒè¯•ã€‚æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é€‰é¢˜ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚

åŒ»ç–—é¢†åŸŸåˆ™ä½¿ç”¨é€šç”¨é¢†åŸŸæ•°æ®é›†ï¼ˆC-Evalã€MMLUã€CMMLUï¼‰ä¸­çš„åŒ»å­¦ç›¸å…³å­¦ç§‘ã€[MedQA](https://arxiv.org/abs/2009.13081) å’Œ [MedMCQA](https://medmcqa.github.io/)ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- ä¸ºäº†æµ‹è¯•æ–¹ä¾¿ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† C-Eval çš„ val é›†è¿›è¡Œæµ‹è¯•ã€‚
- MedQA æ•°æ®é›†æ¥æºäºç¾å›½ã€ä¸­å›½çš„åŒ»å­¦è€ƒè¯•ã€‚æˆ‘ä»¬æµ‹è¯•äº† [MedQAæ•°æ®é›†](https://huggingface.co/datasets/bigbio/med_qa) ä¸­çš„ USMLE å’Œ MCMLE ä¸¤ä¸ªå­é›†ï¼Œå¹¶é‡‡ç”¨äº†äº”ä¸ªå€™é€‰çš„ç‰ˆæœ¬ã€‚
- MedMCQA æ•°æ®é›†æ¥æºäºå°åº¦åŒ»å­¦é™¢çš„å…¥å­¦è€ƒè¯•ã€‚æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é€‰é¢˜ã€‚ç”±äº test é›†æ²¡æœ‰ç­”æ¡ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ dev é›†è¿›è¡Œæµ‹è¯•ã€‚
- é€šç”¨é¢†åŸŸæ•°æ®é›†åŒ…å«çš„åŒ»å­¦ç›¸å…³å­¦ç§‘å¦‚ä¸‹ï¼š
    - C-Eval: clinical_medicine, basic_medicine
    - MMLU: clinical_knowledge, anatomy, college_medicine, college_biology, nutrition, virology, medical_genetics, professional_medicine
    - CMMLU: anatomy, clinical_knowledge, college_medicine, genetics, nutrition, traditional_chinese_medicine, virology 

æˆ‘ä»¬å¯¹ä»¥ä¸Šæ•°æ®é›†è¿›è¡Œäº† 5-shot æµ‹è¯•ã€‚

### 7B æ¨¡å‹ç»“æœ

|                       | **JEC-QA** | **CEval-MMLU-CMMLU** | **MedQA-USMLE** | **MedQA-MCMLE** | **MedMCQA** |
|:---------------------:|:----------:|:--------------------:|:---------------:|:---------------:|:-----------:|
|                       | 5-shot     | 5-shot               | 5-shot          | 5-shot          | 5-shot      |
| **GPT-4**             | 59.32      | 77.16                | 80.28           | 74.58           | 72.51       |
| **GPT-3.5 Turbo**     | 42.31      | 61.17                | 53.81           | 52.92           | 56.25       |
| **LLaMA-7B**          | 27.45      | 33.34                | 24.12           | 21.72           | 27.45       |
| **LLaMA2-7B**         | 29.20      | 36.75                | 27.49           | 24.78           | 37.93       |
| **MPT-7B**            | 27.45      | 26.67                | 16.97           | 19.79           | 31.96       |
| **Falcon-7B**         | 23.66      | 25.33                | 21.29           | 18.07           | 33.88       |
| **ChatGLM2-6B**       | 40.76      | 44.54                | 26.24           | 45.53           | 30.22       |
| **Baichuan-7B**       | 34.64      | 42.37                | 27.42           | 39.46           | 31.39       |
| **Baichuan2-7B-Base** | 44.46      | 56.39                | 32.68           | 54.93           | 41.73       |

### 13B æ¨¡å‹ç»“æœ

|                             | **JEC-QA** | **CEval-MMLU-CMMLU** | **MedQA-USMLE** | **MedQA-MCMLE** | **MedMCQA** |
|:---------------------------:|:----------:|:--------------------:|:---------------:|:---------------:|:-----------:|
|                             | 5-shot     |  5-shot              |  5-shot         |  5-shot         | 5-shot      |
| **GPT-4**                   | 59.32      | 77.16                | 80.28           | 74.58           | 72.51       |
| **GPT-3.5 Turbo**           | 42.31      | 61.17                | 53.81           | 52.92           | 56.25       |
| **LLaMA-13B**               | 27.54      | 35.14                | 28.83           | 23.38           | 39.52       |
| **LLaMA2-13B**              | 34.08      | 47.42                | 35.04           | 29.74           | 42.12       |
| **Vicuna-13B**              | 28.38      | 40.99                | 34.80           | 27.67           | 40.66       |
| **Chinese-Alpaca-Plus-13B** | 35.32      | 46.31                | 27.49           | 32.66           | 35.87       |
| **XVERSE-13B**              | 46.42      | 58.08                | 32.99           | 58.76           | 41.34       |
| **Baichuan-13B-Base**       | 41.34      | 51.77                | 29.07           | 43.67           | 39.60       |
| **Baichuan2-13B-Base**      | 47.40      | 59.33                | 40.38           | 61.62           | 42.86       |

## æ•°å­¦ã€ä»£ç 

æ•°å­¦é¢†åŸŸæˆ‘ä»¬ä½¿ç”¨ [OpenCompass](https://opencompass.org.cn/) è¯„ä¼°æ¡†æ¶ï¼Œå¯¹ [GSM8K](https://huggingface.co/datasets/gsm8k) å’Œ [MATH](https://huggingface.co/datasets/competition_math) æ•°æ®é›†è¿›è¡Œäº† 4-shot æµ‹è¯•ã€‚

- GSM8K æ˜¯ç”± OpenAI å‘å¸ƒçš„ä¸€ä¸ªç”± 8.5K é«˜è´¨é‡çš„è¯­è¨€å¤šæ ·åŒ–çš„å°å­¦æ•°å­¦åº”ç”¨é¢˜ç»„æˆçš„æ•°æ®é›†ï¼Œè¦æ±‚æ ¹æ®ç»™å®šçš„åœºæ™¯å’Œä¸¤ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œé€‰æ‹©æœ€åˆç†çš„æ–¹æ¡ˆã€‚
- MATH æ•°æ®é›†åŒ…å« 12,500 ä¸ªæ•°å­¦é—®é¢˜ï¼ˆå…¶ä¸­ 7500 ä¸ªå±äºè®­ç»ƒé›†ï¼Œ5000 ä¸ªå±äºæµ‹è¯•é›†ï¼‰ï¼Œè¿™äº›é—®é¢˜æ”¶é›†è‡ª AMC 10ã€AMC 12ã€AIME ç­‰æ•°å­¦ç«èµ›ã€‚

ä»£ç é¢†åŸŸåˆ™é‡‡ç”¨äº† [HumanEval](https://huggingface.co/datasets/openai_humaneval) å’Œ [MBPP](https://huggingface.co/datasets/mbpp) æ•°æ®é›†ã€‚æˆ‘ä»¬ä½¿ç”¨ OpenCompassï¼Œå¯¹ HumanEval è¿›è¡Œäº† 0-shot æµ‹è¯•ï¼ŒMBPP æ•°æ®é›†è¿›è¡Œäº† 3-shot æµ‹è¯•ã€‚
- HumanEval ä¸­çš„ç¼–ç¨‹ä»»åŠ¡åŒ…æ‹¬æ¨¡å‹è¯­è¨€ç†è§£ã€æ¨ç†ã€ç®—æ³•å’Œç®€å•æ•°å­¦ï¼Œä»¥è¯„ä¼°æ¨¡å‹åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå¹¶è¡¡é‡æ¨¡å‹çš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚
- MBPP åŒ…æ‹¬ 974 ä¸ª Python çŸ­å‡½æ•°ã€ç¨‹åºçš„æ–‡å­—æè¿°ä»¥åŠç”¨äºæ£€æŸ¥åŠŸèƒ½æ­£ç¡®æ€§çš„æµ‹è¯•ç”¨ä¾‹çš„æ•°æ®é›†ã€‚

### 7B æ¨¡å‹ç»“æœ

|                       | **GSM8K** | **MATH** | **HumanEval** | **MBPP** |
|:---------------------:|:---------:|:--------:|:-------------:|:--------:|
|                       |  4-shot   | 4-shot   |  0-shot       |  3-shot  |
| **GPT-4**             |   89.99   | 40.20    | 69.51         |  63.60   |
| **GPT-3.5 Turbo**     |   57.77   | 13.96    | 52.44         |  61.40   |
| **LLaMA-7B**          |   9.78    | 3.02     | 11.59         |  14.00   |
| **LLaMA2-7B**         |   16.22   | 3.24     | 12.80         |  14.80   |
| **MPT-7B**            |   8.64    | 2.90     | 14.02         |  23.40   |
| **Falcon-7B**         |   5.46    | 1.68     | -             |  10.20   |
| **ChatGLM2-6B**       |   28.89   | 6.40     | 9.15          |   9.00   |
| **Baichuan-7B**       |   9.17    | 2.54     | 9.20          |   6.60   |
| **Baichuan2-7B-Base** |   24.49   | 5.58     | 18.29         |  24.20   |

### 13B æ¨¡å‹ç»“æœ

|                             | **GSM8K** | **MATH** | **HumanEval** | **MBPP** |
|:---------------------------:|:---------:|:--------:|:-------------:|:--------:|
|                             |  4-shot   | 4-shot   |  0-shot       |  3-shot  |
| **GPT-4**                   |   89.99   | 40.20    | 69.51         |  63.60   |
| **GPT-3.5 Turbo**           |   57.77   | 13.96    | 52.44         |  61.40   |
| **LLaMA-13B**               |   20.55   | 3.68     | 15.24         |  21.40   |
| **LLaMA2-13B**              |   28.89   | 4.96     | 15.24         |  27.00   |
| **Vicuna-13B**              |   28.13   | 4.36     | 16.46         |  15.00   |
| **Chinese-Alpaca-Plus-13B** |   11.98   | 2.50     | 16.46         |  20.00   |
| **XVERSE-13B**              |   18.20   | 2.18     | 15.85         |  16.80   |
| **Baichuan-13B-Base**       |   26.76   | 4.84     | 11.59         |  22.80   |
| **Baichuan2-13B-Base**      |   52.77   | 10.08    | 17.07         |  30.20   |

## å¤šè¯­è¨€ç¿»è¯‘

æˆ‘ä»¬é‡‡ç”¨äº† [Flores-101](https://huggingface.co/datasets/facebook/flores) æ•°æ®é›†æ¥è¯„ä¼°æ¨¡å‹çš„å¤šè¯­è¨€èƒ½åŠ›ã€‚Flores-101 æ¶µç›–äº†ä¸–ç•Œå„åœ°çš„ 101 ç§è¯­è¨€ã€‚å®ƒçš„æ•°æ®æ¥æºäºæ–°é—»ã€æ—…æ¸¸æŒ‡å—å’Œä¹¦ç±ç­‰å¤šä¸ªä¸åŒé¢†åŸŸã€‚æˆ‘ä»¬é€‰æ‹©äº†è”åˆå›½å®˜æ–¹è¯­è¨€ï¼ˆé˜¿æ‹‰ä¼¯æ–‡ã€ä¸­æ–‡ã€è‹±æ–‡ã€æ³•æ–‡ã€ä¿„æ–‡å’Œè¥¿ç­ç‰™æ–‡ï¼‰ä»¥åŠå¾·æ–‡å’Œæ—¥æ–‡ä½œä¸ºæµ‹è¯•è¯­ç§ã€‚æˆ‘ä»¬ä½¿ç”¨ OpenCompass å¯¹ Flores-101 ä¸­çš„ä¸­-è‹±ã€ä¸­-æ³•ã€ä¸­-è¥¿ç­ç‰™ã€ä¸­-é˜¿æ‹‰ä¼¯ã€ä¸­-ä¿„ã€ä¸­-æ—¥ã€ä¸­-å¾·ç­‰ä¸ƒä¸ªå­ä»»åŠ¡åˆ†åˆ«è¿›è¡Œäº† 8-shot æµ‹è¯•ã€‚

### 7B æ¨¡å‹ç»“æœ

|             | **CN-EN** | **CN-FR** | **CN-ES** | **CN-AR** | **CN-RU** | **CN-JP** | **CN-DE** | Average |
|:---------------------:|:-------:|:-------:|:---------:|:---------:|:-------:|:-------:|:-------:|:-------:|
| **GPT-4**             | 29.94   | 29.56   | 20.01     | 10.76     | 18.62   | 13.26   | 20.83   | 20.43   |
| **GPT-3.5 Turbo**     | 27.67   | 26.15   | 19.58     | 10.73     | 17.45   | 1.82    | 19.70   | 17.59   |
| **LLaMA-7B**          | 17.27   | 12.02   | 9.54      | 0.00      | 4.47    | 1.41    | 8.73    | 7.63    |
| **LLaMA2-7B**         | 25.76   | 15.14   | 11.92     | 0.79      | 4.99    | 2.20    | 10.15   | 10.14   |
| **MPT-7B**            | 20.77   | 9.53    | 8.96      | 0.10      | 3.54    | 2.91    | 6.54    | 7.48    |
| **Falcon-7B**         | 22.13   | 15.67   | 9.28      | 0.11      | 1.35    | 0.41    | 6.41    | 7.91    |
| **ChatGLM2-6B**       | 22.28   | 9.42    | 7.77      | 0.64      | 1.78    | 0.26    | 4.61    | 6.68    |
| **Baichuan-7B**       | 25.07   | 16.51   | 12.72     | 0.41      | 6.66    | 2.24    | 9.86    | 10.50   |
| **Baichuan2-7B-Base** | 27.27   | 20.87   | 16.17     | 1.39      | 11.21   | 3.11    | 12.76   | 13.25   |

### 13B æ¨¡å‹ç»“æœ

|                   | **CN-EN** | **CN-FR** | **CN-ES** | **CN-AR** | **CN-RU** | **CN-JP** | **CN-DE** | Average |
|:---------------------------:|:-------:|:-------:|:---------:|:---------:|:-------:|:-------:|:-------:|:-------:|
|          **GPT-4**          | 29.94   | 29.56   | 20.01     | 10.76     | 18.62   | 13.26   | 20.83   | 20.43   |
|      **GPT-3.5 Turbo**      | 27.67   | 26.15   | 19.58     | 10.73     | 17.45   | 1.82    | 19.70   | 17.59   |
|        **LLaMA-13B**        | 21.75   | 16.16   | 13.29     | 0.58      | 7.61    | 0.41    | 10.66   | 10.07   |
|       **LLaMA2-13B**        | 25.44   | 19.25   | 17.49     | 1.38      | 10.34   | 0.13    | 11.13   | 12.17   |
|       **Vicuna-13B**        | 22.63   | 18.04   | 14.67     | 0.70      | 9.27    | 3.59    | 10.25   | 11.31   |
| **Chinese-Alpaca-Plus-13B** | 22.53   | 13.82   | 11.29     | 0.28      | 1.52    | 0.31    | 8.13    | 8.27    |
|       **XVERSE-13B**        | 29.26   | 24.03   | 16.67     | 2.78      | 11.61   | 3.08    | 14.26   | 14.53   |
|    **Baichuan-13B-Base**    | 30.24   | 20.90   | 15.92     | 0.98      | 9.65    | 2.64    | 12.00   | 13.19   |
|    **Baichuan2-13B-Base**   | 30.61   | 22.11   | 17.27     | 2.39      | 14.17   | 11.58   | 14.53   | 16.09   |

# æ¨ç†å’Œéƒ¨ç½²

æ¨ç†æ‰€éœ€çš„æ¨¡å‹æƒé‡ã€æºç ã€é…ç½®å·²å‘å¸ƒåœ¨ Hugging Faceï¼Œä¸‹è½½é“¾æ¥è§æœ¬æ–‡æ¡£æœ€å¼€å§‹çš„è¡¨æ ¼ã€‚æˆ‘ä»¬åœ¨æ­¤ç¤ºèŒƒå¤šç§æ¨ç†æ–¹å¼ã€‚ç¨‹åºä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½æ‰€éœ€èµ„æºã€‚

## å®‰è£…ä¾èµ–
```shell
pip install -r requirements.txt
```

## Python ä»£ç æ–¹å¼

### Chat æ¨¡å‹æ¨ç†æ–¹æ³•ç¤ºèŒƒ
```python
>>> import torch
>>> from transformers import AutoModelForCausalLM, AutoTokenizer
>>> from transformers.generation.utils import GenerationConfig
>>> tokenizer = AutoTokenizer.from_pretrained("baichuan-inc/Baichuan2-13B-Chat", use_fast=False, trust_remote_code=True)
>>> model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-13B-Chat", device_map="auto", torch_dtype=torch.bfloat16, trust_remote_code=True)
>>> model.generation_config = GenerationConfig.from_pretrained("baichuan-inc/Baichuan2-13B-Chat")
>>> messages = []
>>> messages.append({"role": "user", "content": "è§£é‡Šä¸€ä¸‹â€œæ¸©æ•…è€ŒçŸ¥æ–°â€"})
>>> response = model.chat(tokenizer, messages)
>>> print(response)
"æ¸©æ•…è€ŒçŸ¥æ–°"æ˜¯ä¸€å¥ä¸­å›½å¤ä»£çš„æˆè¯­ï¼Œå‡ºè‡ªã€Šè®ºè¯­Â·ä¸ºæ”¿ã€‹ç¯‡ã€‚è¿™å¥è¯çš„æ„æ€æ˜¯ï¼šé€šè¿‡å›é¡¾è¿‡å»ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æ–°çš„çŸ¥è¯†å’Œç†è§£ã€‚æ¢å¥è¯è¯´ï¼Œå­¦ä¹ å†å²å’Œç»éªŒå¯ä»¥è®©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£ç°åœ¨å’Œæœªæ¥ã€‚

è¿™å¥è¯é¼“åŠ±æˆ‘ä»¬åœ¨å­¦ä¹ å’Œç”Ÿæ´»ä¸­ä¸æ–­åœ°å›é¡¾å’Œåæ€è¿‡å»çš„ç»éªŒï¼Œä»è€Œè·å¾—æ–°çš„å¯ç¤ºå’Œæˆé•¿ã€‚é€šè¿‡é‡æ¸©æ—§çš„çŸ¥è¯†å’Œç»å†ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°æ–°çš„è§‚ç‚¹å’Œç†è§£ï¼Œä»è€Œæ›´å¥½åœ°åº”å¯¹ä¸æ–­å˜åŒ–çš„ä¸–ç•Œå’ŒæŒ‘æˆ˜ã€‚
```

### Base æ¨¡å‹æ¨ç†æ–¹æ³•ç¤ºèŒƒ
```python
>>> from transformers import AutoModelForCausalLM, AutoTokenizer
>>> tokenizer = AutoTokenizer.from_pretrained("baichuan-inc/Baichuan2-13B-Base", trust_remote_code=True)
>>> model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-13B-Base", device_map="auto", trust_remote_code=True)
>>> inputs = tokenizer('ç™»é¹³é›€æ¥¼->ç‹ä¹‹æ¶£\nå¤œé›¨å¯„åŒ—->', return_tensors='pt')
>>> inputs = inputs.to('cuda:0')
>>> pred = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)
>>> print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))
ç™»é¹³é›€æ¥¼->ç‹ä¹‹æ¶£
å¤œé›¨å¯„åŒ—->æå•†éš
```

> åœ¨ä¸Šè¿°ä¸¤æ®µä»£ç ä¸­ï¼Œæ¨¡å‹åŠ è½½æŒ‡å®š `device_map='auto'`ï¼Œä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨æ˜¾å¡ã€‚å¦‚éœ€æŒ‡å®šä½¿ç”¨çš„è®¾å¤‡ï¼Œå¯ä»¥ä½¿ç”¨ç±»ä¼¼ `export CUDA_VISIBLE_DEVICES=0,1`ï¼ˆä½¿ç”¨äº†0ã€1å·æ˜¾å¡ï¼‰çš„æ–¹å¼æ§åˆ¶ã€‚

## å‘½ä»¤è¡Œå·¥å…·æ–¹å¼

```shell
python cli_demo.py
```
æœ¬å‘½ä»¤è¡Œå·¥å…·æ˜¯ä¸º Chat åœºæ™¯è®¾è®¡ï¼Œå› æ­¤æˆ‘ä»¬ä¸æ”¯æŒä½¿ç”¨è¯¥å·¥å…·è°ƒç”¨ Base æ¨¡å‹ã€‚

## ç½‘é¡µ demo æ–¹å¼

ä¾é  streamlit è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä¼šåœ¨æœ¬åœ°å¯åŠ¨ä¸€ä¸ª web æœåŠ¡ï¼ŒæŠŠæ§åˆ¶å°ç»™å‡ºçš„åœ°å€æ”¾å…¥æµè§ˆå™¨å³å¯è®¿é—®ã€‚æœ¬ç½‘é¡µ demo å·¥å…·æ˜¯ä¸º Chat åœºæ™¯è®¾è®¡ï¼Œå› æ­¤æˆ‘ä»¬ä¸æ”¯æŒä½¿ç”¨è¯¥å·¥å…·è°ƒç”¨ Base æ¨¡å‹ã€‚

```shell
streamlit run web_demo.py
```

## Baichuan2-13B-Chat ç¤ºä¾‹è¾“å‡º

<details><summary><b>ä»£ç </b></summary>

`````
ç”¨æˆ·ï¼šæ‰¾åˆ°ä¸‹åˆ—æ•°ç»„çš„ä¸­ä½æ•°[3.1,6.2,1.3,8.4,10.5,11.6,2.1]ï¼Œè¯·ç”¨pythonä»£ç å®Œæˆä»¥ä¸ŠåŠŸèƒ½

Baichuan 2ï¼šdef find_median(numbers):
    numbers.sort()
    length = len(numbers)
    if length % 2 == 0:
        return (numbers[length // 2 - 1] + numbers[length // 2]) / 2
    else:
        return numbers[length // 2]
numbers = [3.1, 6.2, 1.3, 8.4, 10.5, 11.6, 2.1]
print(find_median(numbers))
`````

</details>

<details><summary><b>æ•°å­¦</b></summary>

`````
ç”¨æˆ·ï¼šé¸¡å’Œå…”åœ¨ä¸€ä¸ªç¬¼å­é‡Œï¼Œå…±æœ‰26ä¸ªå¤´ï¼Œ68åªè„šï¼Œé‚£ä¹ˆé¸¡æœ‰å¤šå°‘åªï¼Œå…”æœ‰å¤šå°‘åªï¼Ÿ

Baichuan 2ï¼šæˆ‘ä»¬å¯ä»¥ç”¨ä»£æ•°æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å‡è®¾é¸¡çš„æ•°é‡ä¸ºxï¼Œå…”å­çš„æ•°é‡ä¸ºyã€‚æ ¹æ®é¢˜ç›®ç»™å‡ºçš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä»¥ä¸‹ä¸¤ä¸ªæ–¹ç¨‹ï¼š

1. x + y = 26 (å¤´çš„æ€»æ•°)
2. 2x + 4y = 68 (è„šçš„æ€»æ•°)

ç°åœ¨æˆ‘ä»¬éœ€è¦è§£è¿™ä¸ªäºŒå…ƒä¸€æ¬¡æ–¹ç¨‹ç»„ã€‚é¦–å…ˆä»ç¬¬ä¸€ä¸ªæ–¹ç¨‹ä¸­è§£å‡ºxï¼š

x = 26 - y

ç„¶åå°†xçš„è¡¨è¾¾å¼ä»£å…¥ç¬¬äºŒä¸ªæ–¹ç¨‹ï¼š

2(26 - y) + 4y = 68
52 - 2y + 4y = 68
2y = 16

æ¥ä¸‹æ¥æˆ‘ä»¬æ±‚è§£yçš„å€¼ï¼š

y = 16 / 2
y = 8

ç°åœ¨æˆ‘ä»¬å¾—åˆ°äº†å…”å­çš„æ•°é‡æ˜¯8åªã€‚å°†yçš„å€¼ä»£å…¥xçš„è¡¨è¾¾å¼æ±‚å¾—é¸¡çš„æ•°é‡ï¼š

x = 26 - 8
x = 18

æ‰€ä»¥é¸¡æœ‰18åªï¼Œå…”å­æœ‰8åªã€‚
`````

</details>

<details><summary><b>æŒ‡ä»¤è·Ÿéš</b></summary>

`````
ç”¨æˆ·ï¼šä»ç°åœ¨å¼€å§‹ï¼Œè¯·ä½ å°†æˆ‘æ¥ä¸‹æ¥è¯´çš„æ¯ä¸€å¥è¯ç¿»è¯‘æˆè‹±è¯­ï¼Œå‡†å¤‡å¥½äº†å—ï¼Ÿ

Baichuan 2ï¼šI'm ready to translate every word you say next into English.

ç”¨æˆ·ï¼šä½ å¥½

Baichuan 2ï¼šHello

ç”¨æˆ·ï¼šæˆ‘æ˜¯Baichuan 2ï¼Œå¾ˆé«˜å…´è®¤è¯†å¤§å®¶

Baichuan 2ï¼šI am Baichuan 2, and I am very happy to meet everyone.

ç”¨æˆ·ï¼šå¸Œæœ›é€šè¿‡å¤§å®¶çš„å…±åŒåŠªåŠ›ï¼Œæ—©æ—¥è¿æ¥AGIæ—¶ä»£çš„åˆ°æ¥

Baichuan 2ï¼šI hope through the joint efforts of all of us, we can welcome the arrival of the AGI era as soon as possible.
`````
</details>

<details><summary><b>è§£é¢˜</b></summary>

`````
ç”¨æˆ·ï¼šä»¥ä¸‹ç‰©ç†å¸¸è¯†é¢˜ç›®ï¼Œå“ªä¸€ä¸ªæ˜¯é”™è¯¯çš„?A.åœ¨è‡ªç„¶ç¯å¢ƒä¸‹ï¼Œå£°éŸ³åœ¨å›ºä½“ä¸­ä¼ æ’­é€Ÿåº¦æœ€å¿«ã€‚B.ç‰›é¡¿ç¬¬ä¸€å®šå¾‹:ä¸€ä¸ªç‰©ä½“å¦‚æœä¸å—åŠ›ä½œç”¨ï¼Œå°†ä¿æŒé™æ­¢æˆ–åŒ€é€Ÿç›´çº¿è¿åŠ¨çš„çŠ¶æ€ã€‚C.ç‰›é¡¿ç¬¬ä¸‰å®šå¾‹:å¯¹äºæ¯ä¸ªä½œç”¨åŠ›ï¼Œéƒ½æœ‰ä¸€ä¸ªç›¸ç­‰è€Œåå‘çš„åä½œç”¨åŠ›ã€‚D.å£°éŸ³åœ¨ç©ºæ°”ä¸­çš„ä¼ æ’­é€Ÿåº¦ä¸º1000m/sã€‚

Baichuan 2ï¼šæœ¬é¢˜è€ƒæŸ¥ç‰©ç†åŸºæœ¬æ¦‚å¿µå’ŒåŸç†çš„ç†è§£å’Œåº”ç”¨èƒ½åŠ›ã€‚
Aé¡¹ï¼šå£°éŸ³çš„ä¼ æ’­éœ€è¦ä»‹è´¨ï¼Œåœ¨å›ºä½“ã€æ¶²ä½“å’Œæ°”ä½“çš„ä¸‰ç§ä»‹è´¨ä¸­ï¼Œå£°éŸ³åœ¨å›ºä½“ä¸­çš„ä¼ æ’­é€Ÿåº¦æ˜¯æœ€å¿«çš„ï¼Œæ•…Aæ­£ç¡®ï¼› Bé¡¹ï¼šç‰›é¡¿ç¬¬ä¸€å®šå¾‹æ˜¯æƒ¯æ€§å®šå¾‹ï¼Œå…¶å†…å®¹æ˜¯ï¼šä¸€ä¸ªç‰©ä½“å¦‚æœæ²¡æœ‰å—åˆ°å¤–åŠ›çš„ä½œç”¨ï¼Œè¦ä¹ˆä¿æŒé™æ­¢çŠ¶æ€ï¼Œè¦ä¹ˆä¿æŒåŒ€é€Ÿç›´çº¿è¿åŠ¨çŠ¶æ€ï¼Œç›´åˆ°æœ‰å¤–åŠ›è¿«ä½¿å®ƒæ”¹å˜è¿åŠ¨çŠ¶æ€ä¸ºæ­¢ï¼Œæ•…Bæ­£ç¡®ï¼› Cé¡¹ï¼šç‰›é¡¿ç¬¬ä¸‰å®šå¾‹çš„å†…å®¹æ˜¯ï¼šå¯¹äºæ¯ä¸€ä¸ªä½œç”¨åŠ›ï¼Œéƒ½æœ‰ä¸€ä¸ªå¤§å°ç›¸ç­‰ã€æ–¹å‘ç›¸åçš„åä½œç”¨åŠ›ï¼Œè¿™ä¸¤ä¸ªåŠ›åˆ†åˆ«ä½œç”¨åœ¨ä¸¤ä¸ªç›¸äº’ä½œç”¨çš„ç‰©ä½“ä¸Šï¼Œæ•…Cé”™è¯¯ï¼› Dé¡¹ï¼šå£°éŸ³åœ¨ç©ºæ°”ä¸­ä»¥æ³¢çš„å½¢å¼ä¼ æ’­ï¼Œå…¶ä¼ æ’­é€Ÿåº¦ä¸ä»‹è´¨çš„æ¸©åº¦ã€æ¹¿åº¦ç­‰å› ç´ æœ‰å…³ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå£°éŸ³åœ¨ç©ºæ°”ä¸­çš„ä¼ æ’­é€Ÿåº¦çº¦ä¸º340m/så·¦å³ï¼Œè€Œä¸æ˜¯1000m/sï¼Œæ•…Dé”™è¯¯ã€‚ å› æ­¤ï¼Œæœ¬é¢˜çš„æ­£ç¡®ç­”æ¡ˆæ˜¯ D ã€‚
`````
`````
ç”¨æˆ·ï¼šI'm Mike ã€‚I am going to have a busy weekendã€‚On Saturdayï¼ŒI am going to learn how to swimã€‚I will go with my fatherã€‚Then we are going to have lunch in the restaurantã€‚In the afternoonï¼Œwe are going to the zooã€‚We are going to see the pandasã€‚On Sundayï¼ŒI will finish my homework in the morningã€‚In the afternoonï¼Œmy parents and I are going to visit my grandparentsã€‚We will have dinner togetherã€‚
é˜…è¯»çŸ­æ–‡ï¼Œåˆ¤æ–­æ­£ç¡®å’Œé”™è¯¯ï¼æ­£ç¡®è¯·å†™Tï¼Œé”™è¯¯è¯·å†™F:
1.Mike is going to have a busy weekend()
2.Mike is going to learn how to swim with his father()
3.They are going to have lunch at home()

Baichuan 2ï¼š1. Tï¼ˆæ­£ç¡®çš„ï¼‰
2. Tï¼ˆæ­£ç¡®çš„ï¼‰
3. Fï¼ˆé”™è¯¯çš„ï¼‰
`````

</details>

## é‡åŒ–éƒ¨ç½²

ä¸ºäº†è®©ä¸åŒçš„ç”¨æˆ·ä»¥åŠä¸åŒçš„å¹³å°éƒ½èƒ½è¿è¡Œ Baichuan 2 æ¨¡å‹ï¼Œæˆ‘ä»¬é’ˆå¯¹ Baichuan 2 æ¨¡å‹åšäº†ç›¸åº”åœ°é‡åŒ–å·¥ä½œï¼ˆåŒ…æ‹¬ Baichuan2-7B-Chat å’Œ Baichuan2-13B-Chatï¼‰ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿé«˜æ•ˆåœ°åœ¨è‡ªå·±çš„å¹³å°éƒ¨ç½² Baichuan 2 æ¨¡å‹ã€‚

### é‡åŒ–æ–¹æ³•

Baichuan 2 çš„é‡‡ç”¨ç¤¾åŒºä¸»æµçš„é‡åŒ–æ–¹æ³•ï¼š[BitsAndBytes](https://github.com/TimDettmers/bitsandbytes)ã€‚è¯¥æ–¹æ³•å¯ä»¥ä¿è¯é‡åŒ–åçš„æ•ˆæœåŸºæœ¬ä¸æ‰ç‚¹ï¼Œç›®å‰å·²ç»é›†æˆåˆ° transformers åº“é‡Œï¼Œå¹¶åœ¨ç¤¾åŒºå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚BitsAndBytes æ”¯æŒ 8bits å’Œ 4bits ä¸¤ç§é‡åŒ–ï¼Œå…¶ä¸­ 4bits æ”¯æŒ FP4 å’Œ NF4 ä¸¤ç§æ ¼å¼ï¼ŒBaichuan 2 é€‰ç”¨ NF4 ä½œä¸º 4bits é‡åŒ–çš„æ•°æ®ç±»å‹ã€‚  
  
åŸºäºè¯¥é‡åŒ–æ–¹æ³•ï¼ŒBaichuan 2 æ”¯æŒåœ¨çº¿é‡åŒ–å’Œç¦»çº¿é‡åŒ–ä¸¤ç§æ¨¡å¼ã€‚

### åœ¨çº¿é‡åŒ–

å¯¹äºåœ¨çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ”¯æŒ 8bits å’Œ 4bits é‡åŒ–ï¼Œä½¿ç”¨æ–¹å¼å’Œ [Baichuan-13B](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat) é¡¹ç›®ä¸­çš„æ–¹å¼ç±»ä¼¼ï¼Œåªéœ€è¦å…ˆåŠ è½½æ¨¡å‹åˆ° CPU çš„å†…å­˜é‡Œï¼Œå†è°ƒç”¨`quantize()`æ¥å£é‡åŒ–ï¼Œæœ€åè°ƒç”¨ `cuda()`å‡½æ•°ï¼Œå°†é‡åŒ–åçš„æƒé‡æ‹·è´åˆ° GPU æ˜¾å­˜ä¸­ã€‚å®ç°æ•´ä¸ªæ¨¡å‹åŠ è½½çš„ä»£ç éå¸¸ç®€å•ï¼Œæˆ‘ä»¬ä»¥ Baichuan2-7B-Chat ä¸ºä¾‹ï¼š

8bits åœ¨çº¿é‡åŒ–:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float16, trust_remote_code=True)
model = model.quantize(8).cuda() 
```
4bits åœ¨çº¿é‡åŒ–:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float16, trust_remote_code=True)
model = model.quantize(4).cuda() 
```
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç”¨ `from_pretrained` æ¥å£çš„æ—¶å€™ï¼Œç”¨æˆ·ä¸€èˆ¬ä¼šåŠ ä¸Š `device_map="auto"`ï¼Œåœ¨ä½¿ç”¨åœ¨çº¿é‡åŒ–æ—¶ï¼Œéœ€è¦å»æ‰è¿™ä¸ªå‚æ•°ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚

### ç¦»çº¿é‡åŒ–

ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬æä¾›äº†ç¦»çº¿é‡åŒ–å¥½çš„ 4bits çš„ç‰ˆæœ¬ [Baichuan2-7B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-4bits/tree/main)ï¼Œä¾›ç”¨æˆ·ä¸‹è½½ã€‚
ç”¨æˆ·åŠ è½½ Baichuan2-7B-Chat-4bits æ¨¡å‹å¾ˆç®€å•ï¼Œåªéœ€è¦æ‰§è¡Œ:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat-4bits", device_map="auto", trust_remote_code=True)
```
å¯¹äº 8bits ç¦»çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ç›¸åº”çš„ç‰ˆæœ¬ï¼Œå› ä¸º Hugging Face transformers åº“æä¾›äº†ç›¸åº”çš„ API æ¥å£ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„å®ç° 8bits é‡åŒ–æ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½ã€‚ç”¨æˆ·å¯ä»¥è‡ªè¡ŒæŒ‰ç…§å¦‚ä¸‹æ–¹å¼å®ç° 8bits çš„æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ï¼š
```python
# Model saving: model_id is the original model directory, and quant8_saved_dir is the directory where the 8bits quantized model is saved.
model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map="auto", trust_remote_code=True)
model.save_pretrained(quant8_saved_dir)
model = AutoModelForCausalLM.from_pretrained(quant8_saved_dir, device_map="auto", trust_remote_code=True)
```

### é‡åŒ–æ•ˆæœ

é‡åŒ–å‰åæ˜¾å­˜å ç”¨å¯¹æ¯” (GPU Mem in GB)ï¼š
| Precision   | Baichuan2-7B |Baichuan2-13B |
|-------------|:------------:|:------------:|
| bf16 / fp16 | 15.3         | 27.5         |
| 8bits       | 8.0          | 16.1         |
| 4bits       | 5.1          | 8.6          |

é‡åŒ–ååœ¨å„ä¸ª benchmark ä¸Šçš„ç»“æœå’ŒåŸå§‹ç‰ˆæœ¬å¯¹æ¯”å¦‚ä¸‹ï¼š

| Model 5-shot           | C-Eval | MMLU | CMMLU |
|------------------------|:------:|:----:|:-----:|
| Baichuan2-13B-Chat      | 56.74  | 57.32| 59.68  |
| Baichuan2-13B-Chat-4bits | 56.05   | 56.24 | 58.82  |
| Baichuan2-7B-Chat       | 54.35   | 52.93 | 54.99  |
| Baichuan2-7B-Chat-4bits | 53.04   | 51.72 | 52.84  |
> C-Eval æ˜¯åœ¨å…¶ val set ä¸Šè¿›è¡Œçš„è¯„æµ‹

å¯ä»¥çœ‹åˆ°ï¼Œ4bits ç›¸å¯¹ bfloat16 ç²¾åº¦æŸå¤±åœ¨ 1 - 2 ä¸ªç™¾åˆ†ç‚¹å·¦å³ã€‚

## CPU éƒ¨ç½²

Baichuan 2 æ¨¡å‹æ”¯æŒ CPU æ¨ç†ï¼Œä½†éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼ŒCPU çš„æ¨ç†é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ã€‚éœ€æŒ‰å¦‚ä¸‹æ–¹å¼ä¿®æ”¹æ¨¡å‹åŠ è½½çš„æ–¹å¼ï¼š
```python
# Taking Baichuan2-7B-Chat as an example
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float32, trust_remote_code=True)
```
## å¯¹ Baichuan 1 çš„æ¨ç†ä¼˜åŒ–è¿ç§»åˆ° Baichuan 2

ç”±äºå¾ˆå¤šç”¨æˆ·åœ¨ Baichuan 1 (Baichuan-7B, Baichuan-13B)ä¸Šåšäº†å¾ˆå¤šä¼˜åŒ–çš„å·¥ä½œï¼Œä¾‹å¦‚ç¼–è¯‘ä¼˜åŒ–ã€é‡åŒ–ç­‰ï¼Œä¸ºäº†å°†è¿™äº›å·¥ä½œé›¶æˆæœ¬åœ°åº”ç”¨äº Baichuan 2ï¼Œç”¨æˆ·å¯ä»¥å¯¹ Baichuan 2 æ¨¡å‹åšä¸€ä¸ªç¦»çº¿è½¬æ¢ï¼Œè½¬æ¢åå°±å¯ä»¥å½“åš Baichuan 1 æ¨¡å‹æ¥ä½¿ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œç”¨æˆ·åªéœ€è¦åˆ©ç”¨ä»¥ä¸‹è„šæœ¬ç¦»çº¿å¯¹ Baichuan 2 æ¨¡å‹çš„æœ€åä¸€å±‚ lm_head åšå½’ä¸€åŒ–ï¼Œå¹¶æ›¿æ¢æ‰`lm_head.weight`å³å¯ã€‚æ›¿æ¢å®Œåï¼Œå°±å¯ä»¥åƒå¯¹ Baichuan 1 æ¨¡å‹ä¸€æ ·å¯¹è½¬æ¢åçš„æ¨¡å‹åšç¼–è¯‘ä¼˜åŒ–ç­‰å·¥ä½œäº†ã€‚
```python
import torch
import os
ori_model_dir = 'your Baichuan 2 model directory'
# To avoid overwriting the original model, it's best to save the converted model to another directory before replacing it
new_model_dir = 'your normalized lm_head weight Baichuan 2 model directory'
model = torch.load(os.path.join(ori_model_dir, 'pytorch_model.bin'))
lm_head_w = model['lm_head.weight']
lm_head_w = torch.nn.functional.normalize(lm_head_w)
model['lm_head.weight'] = lm_head_w
torch.save(model, os.path.join(new_model_dir, 'pytorch_model.bin'))
```

# æ¨¡å‹å¾®è°ƒ

## ä¾èµ–å®‰è£…

```shell
git clone https://github.com/baichuan-inc/Baichuan2.git
cd Baichuan2/fine-tune
pip install -r requirements.txt
```
- å¦‚éœ€ä½¿ç”¨ LoRA ç­‰è½»é‡çº§å¾®è°ƒæ–¹æ³•éœ€é¢å¤–å®‰è£… [peft](https://github.com/huggingface/peft)
- å¦‚éœ€ä½¿ç”¨ xFormers è¿›è¡Œè®­ç»ƒåŠ é€Ÿéœ€é¢å¤–å®‰è£… [xFormers](https://github.com/facebookresearch/xformers)

## å•æœºè®­ç»ƒ

ä¸‹é¢æˆ‘ä»¬ç»™ä¸€ä¸ªå¾®è°ƒ Baichuan2-7B-Base çš„å•æœºè®­ç»ƒä¾‹å­ã€‚

è®­ç»ƒæ•°æ®ï¼š`data/belle_chat_ramdon_10k.json`ï¼Œè¯¥æ ·ä¾‹æ•°æ®æ˜¯ä» [multiturn_chat_0.8M](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M) é‡‡æ ·å‡º 1 ä¸‡æ¡ï¼Œå¹¶ä¸”åšäº†æ ¼å¼è½¬æ¢ã€‚ä¸»è¦æ˜¯å±•ç¤ºå¤šè½®æ•°æ®æ€ä¹ˆè®­ç»ƒï¼Œä¸ä¿è¯æ•ˆæœã€‚

```shell
hostfile=""
deepspeed --hostfile=$hostfile fine-tune.py  \
    --report_to "none" \
    --data_path "data/belle_chat_ramdon_10k.json" \
    --model_name_or_path "baichuan-inc/Baichuan2-7B-Base" \
    --output_dir "output" \
    --model_max_length 512 \
    --num_train_epochs 4 \
    --per_device_train_batch_size 16 \
    --gradient_accumulation_steps 1 \
    --save_strategy epoch \
    --learning_rate 2e-5 \
    --lr_scheduler_type constant \
    --adam_beta1 0.9 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-8 \
    --max_grad_norm 1.0 \
    --weight_decay 1e-4 \
    --warmup_ratio 0.0 \
    --logging_steps 1 \
    --gradient_checkpointing True \
    --deepspeed ds_config.json \
    --bf16 True \
    --tf32 True
```

## å¤šæœºè®­ç»ƒ

å¤šæœºè®­ç»ƒåªéœ€è¦ç»™ä¸€ä¸‹ hostfile ï¼Œå†…å®¹ç±»ä¼¼å¦‚ä¸‹ï¼š
```
ip1 slots=8
ip2 slots=8
ip3 slots=8
ip4 slots=8
....
```
åŒæ—¶åœ¨è®­ç»ƒè„šæœ¬é‡Œé¢æŒ‡å®š hosftfile çš„è·¯å¾„ï¼š
```shell
hostfile="/path/to/hostfile"
deepspeed --hostfile=$hostfile fine-tune.py  \
    --report_to "none" \
    --data_path "data/belle_chat_ramdon_10k.json" \
    --model_name_or_path "baichuan-inc/Baichuan2-7B-Base" \
    --output_dir "output" \
    --model_max_length 512 \
    --num_train_epochs 4 \
    --per_device_train_batch_size 16 \
    --gradient_accumulation_steps 1 \
    --save_strategy epoch \
    --learning_rate 2e-5 \
    --lr_scheduler_type constant \
    --adam_beta1 0.9 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-8 \
    --max_grad_norm 1.0 \
    --weight_decay 1e-4 \
    --warmup_ratio 0.0 \
    --logging_steps 1 \
    --gradient_checkpointing True \
    --deepspeed ds_config.json \
    --bf16 True \
    --tf32 True
```

## è½»é‡åŒ–å¾®è°ƒ

ä»£ç å·²ç»æ”¯æŒè½»é‡åŒ–å¾®è°ƒå¦‚ LoRAï¼Œå¦‚éœ€ä½¿ç”¨ä»…éœ€åœ¨ä¸Šé¢çš„è„šæœ¬ä¸­åŠ å…¥ä»¥ä¸‹å‚æ•°ï¼š
```shell
--use_lora True
```
LoRA å…·ä½“çš„é…ç½®å¯è§ `fine-tune.py` è„šæœ¬ã€‚

ä½¿ç”¨ LoRA å¾®è°ƒåå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤åŠ è½½æ¨¡å‹ï¼š
```python
from peft import AutoPeftModelForCausalLM
model = AutoPeftModelForCausalLM.from_pretrained("output", trust_remote_code=True)
```

# ä¸­é—´ Checkpoints

é™¤äº†è®­ç»ƒäº† 2.6 ä¸‡äº¿ Tokens çš„ Baichuan2-7B-Base æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†åœ¨æ­¤ä¹‹å‰çš„å¦å¤– 11 ä¸ªä¸­é—´ checkpointsï¼ˆåˆ†åˆ«å¯¹åº”è®­ç»ƒäº†çº¦ 0.2 ~ 2.4 ä¸‡äº¿ Tokensï¼‰ä¾›ç¤¾åŒºç ”ç©¶ä½¿ç”¨ï¼ˆ[ä¸‹è½½åœ°å€](https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints)ï¼‰ã€‚ä¸‹å›¾ç»™å‡ºäº†è¿™äº› checkpoints åœ¨ C-Evalã€MMLUã€CMMLU ä¸‰ä¸ª benchmark ä¸Šçš„æ•ˆæœå˜åŒ–ï¼š

<div align="center">
<img src="https://github.com/baichuan-inc/Baichuan2/blob/main/media/checkpoints.jpeg?raw=true" width=50% />
</div>

# ç¤¾åŒºä¸ç”Ÿæ€

**ğŸ“¢ğŸ“¢ğŸ“¢ æˆ‘ä»¬ä¼šåœ¨æ­¤æŒç»­æ›´æ–°ç¤¾åŒºå’Œç”Ÿæ€å¯¹ Baichuan 2 çš„æ”¯æŒ ğŸ˜€ğŸ˜€ğŸ˜€**

## åä¸ºæ˜‡è…¾

### Pytorch æ¡†æ¶

æ¨¡å‹å¾®è°ƒï¼šBaichuan 2 æ”¯æŒåŸºäºæ˜‡è…¾ NPU çš„ PyTorch + DeepSpeed æ¨¡å‹å¾®è°ƒï¼Œå¾®è°ƒæ‰€éœ€çš„ modelingã€READMEã€ç¤ºä¾‹è„šæœ¬å·²å‘å¸ƒï¼š[Baichuan2-7B](https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/PyTorch/built-in/foundation/Baichuan2/7B)ã€Baichuan2-13B æ­£åœ¨é€‚é…ä¸­ã€‚

æ¨ç†éƒ¨ç½²ï¼šBaichuan 2 æ”¯æŒæ˜‡è…¾ NPU æ¨ç†ï¼Œæ¨ç†æ‰€éœ€çš„ modelingã€READMEã€ç¤ºä¾‹è„šæœ¬å·²å‘å¸ƒï¼š[Baichuan2-7B](https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/ACL_PyTorch/built-in/foundation_models/baichuan2/7b)ã€[Baichuan2-13B](https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/ACL_PyTorch/built-in/foundation_models/baichuan2/13b)ã€‚

### MindSpore æ¡†æ¶

[MindFormers]( https://gitee.com/mindspore/mindformers) æ˜¯ä¸€ä¸ªåŸºäºæ˜‡æ€æ¡†æ¶ï¼ˆMindSporeï¼‰å¹¶æ”¯æŒå¤§æ¨¡å‹è®­ç»ƒã€å¾®è°ƒã€è¯„ä¼°ã€æ¨ç†ã€éƒ¨ç½²çš„å…¨æµç¨‹å¼€å‘å¥—ä»¶ï¼Œ[Baichuan2-7B / 13B]( https://gitee.com/mindspore/mindformers/tree/dev/research/baichuan2) å·²é›†æˆäºæ­¤å¥—ä»¶ï¼Œæ”¯æŒç”¨æˆ·è¿›è¡Œæ¨¡å‹å¾®è°ƒã€éƒ¨ç½²ï¼Œå…·ä½“ä½¿ç”¨æ–¹å¼å¯è§ [README]( https://gitee.com/mindspore/mindformers/tree/dev/research/baichuan2/baichuan2.md)ã€‚

### å¤§æ¨¡å‹ä½“éªŒå¹³å°

[æ˜‡æ€å¤§æ¨¡å‹å¹³å°](https://xihe.mindspore.cn) åŸºäºæ˜‡æ€ MindSpore AI æ¡†æ¶ã€MindFormers å¤§æ¨¡å‹å¼€å‘å¥—ä»¶ä¸æ˜‡è…¾ç¡¬ä»¶ç®—åŠ›ï¼Œå°† [Baichuan2-7B](https://xihe.mindspore.cn/modelzoo/baichuan2_7b_chat) å¤§æ¨¡å‹èƒ½åŠ›å¼€æ”¾ç»™å…¬ä¼—ï¼Œæ¬¢è¿å¤§å®¶åœ¨çº¿ä½“éªŒã€‚

## LLaMA-Efficient-Tuning
[LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) å·²æ”¯æŒå¯¹ Baichuan 2 æ¨¡å‹çš„å¾®è°ƒå’Œç»§ç»­è®­ç»ƒã€‚

# å£°æ˜ã€åè®®ã€å¼•ç”¨

## å£°æ˜

æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å¼€å‘å›¢é˜Ÿå¹¶æœªåŸºäº Baichuan 2 æ¨¡å‹å¼€å‘ä»»ä½•åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ iOSã€Androidã€ç½‘é¡µæˆ–ä»»ä½•å…¶ä»–å¹³å°ã€‚æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ä½¿ç”¨è€…ï¼Œä¸è¦åˆ©ç”¨ Baichuan 2 æ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Baichuan 2 æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚

æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨ Baichuan 2 å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

## åè®®
ç¤¾åŒºä½¿ç”¨ Baichuan 2 æ¨¡å‹éœ€è¦éµå¾ª [Apache 2.0](https://github.com/baichuan-inc/Baichuan2/blob/main/LICENSE) å’Œ[ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/resolve/main/Baichuan%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)ã€‚Baichuan 2 æ¨¡å‹æ”¯æŒå•†ä¸šç”¨é€”ï¼Œå¦‚æœæ‚¨è®¡åˆ’å°† Baichuan 2 æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨äºå•†ä¸šç›®çš„ï¼Œè¯·æ‚¨ç¡®è®¤æ‚¨çš„ä¸»ä½“ç¬¦åˆä»¥ä¸‹æƒ…å†µï¼š
  1. æ‚¨æˆ–æ‚¨çš„å…³è”æ–¹çš„æœåŠ¡æˆ–äº§å“çš„æ—¥å‡ç”¨æˆ·æ´»è·ƒé‡ï¼ˆDAUï¼‰ä½äº100ä¸‡ã€‚
  2. æ‚¨æˆ–æ‚¨çš„å…³è”æ–¹ä¸æ˜¯è½¯ä»¶æœåŠ¡æä¾›å•†ã€äº‘æœåŠ¡æä¾›å•†ã€‚
  3. æ‚¨æˆ–æ‚¨çš„å…³è”æ–¹ä¸å­˜åœ¨å°†æˆäºˆæ‚¨çš„å•†ç”¨è®¸å¯ï¼Œæœªç»ç™¾å·è®¸å¯äºŒæ¬¡æˆæƒç»™å…¶ä»–ç¬¬ä¸‰æ–¹çš„å¯èƒ½ã€‚

åœ¨ç¬¦åˆä»¥ä¸Šæ¡ä»¶çš„å‰æä¸‹ï¼Œæ‚¨éœ€è¦é€šè¿‡ä»¥ä¸‹è”ç³»é‚®ç®± opensource@baichuan-inc.com ï¼Œæäº¤ã€ŠBaichuan 2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹è¦æ±‚çš„ç”³è¯·ææ–™ã€‚å®¡æ ¸é€šè¿‡åï¼Œç™¾å·å°†ç‰¹æ­¤æˆäºˆæ‚¨ä¸€ä¸ªéæ’ä»–æ€§ã€å…¨çƒæ€§ã€ä¸å¯è½¬è®©ã€ä¸å¯å†è®¸å¯ã€å¯æ’¤é”€çš„å•†ç”¨ç‰ˆæƒè®¸å¯ã€‚

## å¼•ç”¨
å¦‚éœ€å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œï¼Œè¯·ä½¿ç”¨å¦‚ä¸‹ reference:
```
@article{baichuan2023baichuan2,
  title={Baichuan 2: Open Large-scale Language Models},
  author={Baichuan},
  journal={arXiv preprint arXiv:2309.10305},
  url={https://arxiv.org/abs/2309.10305},
  year={2023}
}
```
