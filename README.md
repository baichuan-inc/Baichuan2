<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->

<div align="center">
<h1>
  Baichuan2
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://modelscope.cn/organization/baichuan-inc" target="_blank">ModelScope</a> â€¢ ğŸ’¬ <a href="https://github.com/baichuan-inc/Baichuan2/blob/main/media/wechat.jpeg?raw=true" target="_blank">WeChat</a>
</p>

<div align="center">

[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/baichuan-inc/Baichuan-7B/blob/main/LICENSE)
<h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> |
        <a href="https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md">English</a>
    <p>
</h4>
</div>

# ç›®å½•

- [ä»‹ç»](#ä»‹ç»)
- [Benchmarkç»“æœ](#Benchmarkç»“æœ)
- [æ¨¡å‹ç»†èŠ‚](#æ¨¡å‹ç»†èŠ‚)
- [æ¨ç†å’Œéƒ¨ç½²](#æ¨ç†å’Œéƒ¨ç½²)
- [åº”ç”¨æ¡ˆä¾‹](#åº”ç”¨æ¡ˆä¾‹)
- [å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒ](#å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒ)
- [ç¤¾åŒºæ”¯æŒ](#ç¤¾åŒºæ”¯æŒ)
- [å£°æ˜](#å£°æ˜)
- [åè®®](#åè®®)

# ä»‹ç»

# Benchmarkç»“æœ

# æ¨ç†å’Œéƒ¨ç½²

æ¨ç†å‰è¯·å®‰è£…ä¾èµ–ï¼š
```shell
pip install -r requirements.txt
```
## é‡åŒ–éƒ¨ç½²

ä¸ºäº†è®©ä¸åŒçš„ç”¨æˆ·ä»¥åŠä¸åŒçš„å¹³å°éƒ½èƒ½è¿è¡ŒBaichuan2æ¨¡å‹ï¼Œæˆ‘ä»¬é’ˆå¯¹Baichuan2æ¨¡å‹åšäº†ç›¸åº”åœ°é‡åŒ–å·¥ä½œ(åŒ…æ‹¬Baichuan2-7B-Chatå’ŒBaichuan2-13B-Chat)ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿé«˜æ•ˆåœ°åœ¨è‡ªå·±çš„å¹³å°éƒ¨ç½²Baichuan2æ¨¡å‹ã€‚

### é‡åŒ–æ–¹æ³•

Baichuan2çš„é‡åŒ–æ–¹æ³•é‡‡ç”¨ç¤¾åŒºä¸»æµçš„é‡åŒ–æ–¹æ³•ï¼š[BitsAndBytesæ–¹æ³•](https://github.com/TimDettmers/bitsandbytes)ã€‚è¯¥æ–¹æ³•å¯ä»¥ä¿è¯é‡åŒ–åçš„æ•ˆæœåŸºæœ¬ä¸æ‰ç‚¹ï¼Œç›®å‰å·²ç»é›†æˆåˆ°transformersåº“é‡Œï¼Œå¹¶åœ¨ç¤¾åŒºå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚BitsAndBytesæ”¯æŒint4å’Œint8ä¸¤ç§é‡åŒ–ï¼Œå…¶ä¸­int4æ”¯æŒFP4å’ŒNF4ä¸¤ç§æ ¼å¼ï¼ŒBaichuan2é€‰ç”¨NF4ä½œä¸º4bité‡åŒ–çš„æ•°æ®ç±»å‹ã€‚  
  
åŸºäºè¯¥é‡åŒ–æ–¹æ³•ï¼ŒBaichuan2æ”¯æŒåœ¨çº¿é‡åŒ–å’Œç¦»çº¿é‡åŒ–ä¸¤ç§æ¨¡å¼ã€‚

### åœ¨çº¿é‡åŒ–

å¯¹äºåœ¨çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ”¯æŒint8å’Œint4é‡åŒ–ï¼Œä½¿ç”¨æ–¹å¼å’Œ[Baichuan-13B](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat)æ–¹å¼ç±»ä¼¼ï¼Œåªéœ€è¦å…ˆåŠ è½½æ¨¡å‹åˆ°CPUçš„å†…å­˜é‡Œï¼Œå†è°ƒç”¨ä¸€ä¸ªquantizeæ¥å£é‡åŒ–ï¼Œæœ€åè°ƒç”¨cuda()å‡½æ•°ï¼Œå°†é‡åŒ–åçš„æƒé‡æ‹·è´åˆ°GPUæ˜¾å­˜ä¸­ã€‚å®ç°æ•´ä¸ªæ¨¡å‹åŠ è½½çš„ä»£ç éå¸¸ç®€å•ï¼Œæˆ‘ä»¬ä»¥Baichuan2-7B-Chatä¸ºä¾‹ï¼š  
int8åœ¨çº¿é‡åŒ–:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float16, trust_remote_code=True)
model = model.quantize(8).cuda() 
```
int4åœ¨çº¿é‡åŒ–:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float16, trust_remote_code=True)
model = model.quantize(4).cuda() 
```
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç”¨from_pretrainedæ¥å£çš„æ—¶å€™ï¼Œç”¨æˆ·ä¸€èˆ¬ä¼šåŠ ä¸Šdevice_map = "auto"ï¼Œåœ¨ä½¿ç”¨åœ¨çº¿é‡åŒ–æ—¶ï¼Œéœ€è¦å»æ‰è¿™ä¸ªå‚æ•°ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚

### ç¦»çº¿é‡åŒ–
ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬æä¾›äº†ç¦»çº¿é‡åŒ–å¥½çš„int4çš„ç‰ˆæœ¬[Baichuan2-7B-Chat-int4](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-int4/tree/main)ï¼Œä¾›ç”¨æˆ·ä¸‹è½½ã€‚
ç”¨æˆ·åŠ è½½Baichuan2-7B-Chat-int4æ¨¡å‹å¾ˆç®€å•ï¼Œåªéœ€è¦æ‰§è¡Œ:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat-int4", device_map="auto", trust_remote_code=True)
```
å¯¹äºint8ç¦»çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ç›¸åº”çš„ç‰ˆæœ¬ï¼Œå› ä¸ºHuggingFace transformersåº“æä¾›äº†ç›¸åº”çš„APIæ¥å£ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„å®ç°int8é‡åŒ–æ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½ã€‚ç”¨æˆ·å¯ä»¥è‡ªè¡ŒæŒ‰ç…§å¦‚ä¸‹æ–¹å¼å®ç°int8çš„æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ï¼š
```python
#æ¨¡å‹ä¿å­˜ï¼Œå…¶ä¸­model_idä¸ºåŸå§‹æ¨¡å‹ç›®å½•ï¼Œquant8_saved_dirä¸ºint8é‡åŒ–åçš„æ¨¡å‹ä¿å­˜ç›®å½•
model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map="auto", trust_remote_code=True)
model.save_pretrained(quant8_saved_dir)

#æ¨¡å‹åŠ è½½
model = AutoModelForCausalLM.from_pretrained(quant8_saved_dir, device_map="auto", trust_remote_code=True)
```
### é‡åŒ–æ•ˆæœ
é‡åŒ–å‰åæ˜¾å­˜å ç”¨å¯¹æ¯”ï¼š
| Precision   | Baichuan2-7B GPU Mem (GB) |Baichuan2-13B GPU Mem (GB) |
|-------------|:------------:|:------------:|
| bf16 / fp16 | 14.0         | 25.9       |
| int8        | 8.0         | 14.2        |
| int4        | 5.1          | 8.6        |

é‡åŒ–ååœ¨å„ä¸ª benchmark ä¸Šçš„ç»“æœå’ŒåŸå§‹ç‰ˆæœ¬å¯¹æ¯”å¦‚ä¸‹ï¼š

| Model 5-shot           | C-Eval | MMLU | CMMLU |
|------------------------|:------:|:----:|:-----:|
| Baichuan2-13B-Chat      | 55.31  | 56.69| 59.28  |
| Baichuan2-13B-Chat-int4 | 54.90   | 55.73 | 58.09  |
| Baichuan2-7B-Chat       | 54.35   | 52.93 | 54.99  |
| Baichuan2-7B-Chat-int4 | 53.04   | 51.72 | 52.84  |

å¯ä»¥çœ‹åˆ°ï¼Œint4ç›¸å¯¹bfloat16æ‰ç‚¹åœ¨1~2ä¸ªç‚¹å·¦å³ã€‚

## CPUéƒ¨ç½²
Baichuan2æ¨¡å‹æ”¯æŒCPUæ¨ç†ï¼Œä½†éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼ŒCPUçš„æ¨ç†é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ã€‚éœ€æŒ‰å¦‚ä¸‹æ–¹å¼ä¿®æ”¹æ¨¡å‹åŠ è½½çš„æ–¹å¼ï¼š
```python
#ä»¥Baichuan2-7B-Chatä¸ºä¾‹
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float32, trust_remote_code=True)
```
## Baichuan2ç›¸å¯¹Baichuan1æ¨ç†è¿ç§»
ç”±äºå¾ˆå¤šç”¨æˆ·åœ¨Baichuan1ä¸Šåšäº†å¾ˆå¤šä¼˜åŒ–çš„å·¥ä½œï¼Œä¾‹å¦‚ç¼–è¯‘ä¼˜åŒ–ã€é‡åŒ–ç­‰ï¼Œä¸ºäº†å°†è¿™äº›å·¥ä½œé›¶æˆæœ¬åœ°åº”ç”¨äºBaichuan2ï¼Œç”¨æˆ·å¯ä»¥å¯¹Baichuan2æ¨¡å‹åš1ä¸ªç¦»çº¿è½¬æ¢ï¼Œè½¬æ¢åå°±å¯ä»¥å½“åšBaichuan1æ¨¡å‹æ¥ä½¿ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œç”¨æˆ·åªéœ€è¦åˆ©ç”¨ä»¥ä¸‹è„šæœ¬ç¦»çº¿å¯¹Baichuan2æ¨¡å‹çš„æœ€åä¸€å±‚lm_headåšå½’ä¸€åŒ–ï¼Œå¹¶æ›¿æ¢æ‰â€lm_head.weightâ€œå³å¯ã€‚æ›¿æ¢å®Œåï¼Œå°±å¯ä»¥åƒå¯¹Baichuan1æ¨¡å‹ä¸€æ ·å¯¹è½¬æ¢åçš„æ¨¡å‹åšç¼–è¯‘ä¼˜åŒ–ç­‰å·¥ä½œäº†ã€‚
```python
import torch
import os
ori_model_dir = 'your baichuan2 model directory'
#ä¸ºäº†ä¸è¦†ç›–åŸå§‹æ¨¡å‹ï¼Œæœ€å¥½å°†è½¬æ¢åçš„æ¨¡å‹saveåˆ°å¦ä¸€ä¸ªç›®å½•å†æ›¿æ¢
new_model_dir = 'your normalized lm_head weight baichuan2 model directory'
model = torch.load(os.path.join(ori_model_dir, 'pytorch_model.bin'))
lm_head_w = model['lm_head.weight']
lm_head_w = torch.nn.functional.normalize(lm_head_w)
model['lm_head.weight'] = lm_head_w
torch.save(model, os.path.join(new_model_dir, 'pytorch_model.bin'))
```
# åº”ç”¨æ¡ˆä¾‹

# å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒ

## ä¾èµ–å®‰è£…
```shell
git clone https://github.com/baichuan-inc/Baichuan2.git
cd Baichuan2/finetune
pip install -r requirements.txt
```
- å¦‚éœ€ä½¿ç”¨loraç­‰è½»é‡çº§å¾®è°ƒæ–¹æ³•éœ€é¢å¤–å®‰è£…peft
- å¦‚éœ€ä½¿ç”¨Xformersè¿›è¡Œè®­ç»ƒåŠ é€Ÿéœ€é¢å¤–å®‰è£…xformers

## å•æœºè®­ç»ƒ

ä¸‹é¢æˆ‘ä»¬ç»™ä¸€ä¸ªå¾®è°ƒBaichuan2-7B-Baseçš„å•æœºè®­ç»ƒä¾‹å­ã€‚

è®­ç»ƒæ•°æ®ï¼šdata/belle_chat_ramdon_10k.jsonï¼Œè¯¥æ ·ä¾‹æ•°æ®æ˜¯ä»[multiturn_chat_0.8M](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)é‡‡æ ·å‡º1ä¸‡æ¡ï¼Œå¹¶ä¸”åšäº†æ ¼å¼è½¬æ¢ã€‚ä¸»è¦æ˜¯å±•ç¤ºå¤šè½®æ•°æ®æ€ä¹ˆè®­ç»ƒï¼Œä¸ä¿è¯æ•ˆæœã€‚


```shell
hostfile=""  # å•æœº
# hostfile="/path/to/hostfile"  # å¤šæœº
deepspeed --hostfile=$hostfile sft.py  \
    --report_to "none" \
    --data_path "data/belle_chat_ramdon_10k.json" \
    --model_name_or_path "Baichuan/Baichuan2-7B-Base" \
    --output_dir "output" \
    --model_max_length 512 \
    --num_train_epochs 4 \
    --per_device_train_batch_size 16 \
    --gradient_accumulation_steps 1 \
    --save_strategy epoch \
    --learning_rate 2e-5 \
    --lr_scheduler_type constant \
    --adam_beta1 0.9 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-8 \
    --max_grad_norm 1.0 \
    --weight_decay 1e-4 \
    --warmup_ratio 0.0 \
    --logging_steps 1 \
    --gradient_checkpointing True \
    --deepspeed ds_config.json \
    --bf16 True \
    --tf32 True
```

## å¤šæœºè®­ç»ƒ

å¤šæœºè®­ç»ƒåªéœ€è¦ç»™ä¸€ä¸‹hostfileï¼Œå†…å®¹å¦‚ä¸‹ï¼š
```
ip1 slots=8
ip2 slots=8
ip3 slots=8
ip4 slots=8
```
åŒæ—¶åœ¨è®­ç»ƒè„šæœ¬é‡Œé¢æŒ‡å®šhosftfileçš„è·¯å¾„ï¼š
```shell
hostfile="/path/to/hostfile"  # å¤šæœº
deepspeed --hostfile=$hostfile sft.py  \
    --report_to "none" \
    --data_path "data/belle_chat_ramdon_10k.json" \
    --model_name_or_path "Baichuan/Baichuan2-7B-Base" \
    --output_dir "output" \
    --model_max_length 512 \
    --num_train_epochs 4 \
    --per_device_train_batch_size 16 \
    --gradient_accumulation_steps 1 \
    --save_strategy epoch \
    --learning_rate 2e-5 \
    --lr_scheduler_type constant \
    --adam_beta1 0.9 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-8 \
    --max_grad_norm 1.0 \
    --weight_decay 1e-4 \
    --warmup_ratio 0.0 \
    --logging_steps 1 \
    --gradient_checkpointing True \
    --deepspeed ds_config.json \
    --bf16 True \
    --tf32 True
```

## è½»é‡åŒ–å¾®è°ƒ

ä»£ç å·²ç»æ”¯æŒè½»é‡åŒ–å¾®è°ƒå¦‚Loraï¼Œå¦‚éœ€ä½¿ç”¨ä»…éœ€åœ¨ä¸Šé¢çš„è„šæœ¬ä¸­åŠ å…¥ä»¥ä¸‹å‚æ•°
```shell
--use_lora True
```
loraå…·ä½“çš„é…ç½®å¯è§finetune.pyè„šæœ¬ã€‚
ä½¿ç”¨loraå¾®è°ƒåå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤åŠ è½½æ¨¡å‹
```python
from peft import AutoPeftModelForCausalLM

model = AutoPeftModelForCausalLM.from_pretrained("output", trust_remote_code=True)
```
# ç¤¾åŒºæ”¯æŒ

# å£°æ˜

æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å¼€å‘å›¢é˜Ÿå¹¶æœªåŸºäº Baichuan2 æ¨¡å‹å¼€å‘ä»»ä½•åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ iOSã€Androidã€ç½‘é¡µæˆ–ä»»ä½•å…¶ä»–å¹³å°ã€‚æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ä½¿ç”¨è€…ï¼Œä¸è¦åˆ©ç”¨ Baichuan2 æ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Baichuan2 æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚

æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨ Baichuan2 å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

# åè®®
å¯¹æœ¬ä»“åº“æºç çš„ä½¿ç”¨éµå¾ªå¼€æºè®¸å¯åè®® [Apache 2.0](https://github.com/baichuan-inc/Baichuan-13B/blob/main/LICENSE)ã€‚å¯¹ Baichuan2 æ¨¡å‹çš„ç¤¾åŒºä½¿ç”¨è§[ã€ŠBaichuan2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat/resolve/main/Baichuan2%20%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)ã€‚Baichuan2 æ”¯æŒå•†ç”¨ã€‚å¦‚æœå°† Baichuan2 æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç”¨é€”ï¼Œè¯·æ‚¨æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è”ç³»è®¸å¯æ–¹ï¼Œä»¥è¿›è¡Œç™»è®°å¹¶å‘è®¸å¯æ–¹ç”³è¯·ä¹¦é¢æˆæƒï¼šè”ç³»é‚®ç®± <opensource@baichuan-inc.com>ã€‚
