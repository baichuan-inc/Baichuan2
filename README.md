<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->

<div align="center">
<h1>
  Baichuan2
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/baichuan-inc/" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://modelscope.cn/organization/baichuan-inc" target="_blank">ModelScope</a> â€¢ ğŸ’¬ <a href="https://github.com/baichuan-inc/Baichuan2/blob/main/media/wechat.jpeg?raw=true" target="_blank">WeChat</a>
</p>

<div align="center">

[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/baichuan-inc/Baichuan2/blob/main/LICENSE)
<h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> |
        <a href="https://github.com/baichuan-inc/Baichuan2/blob/main/README_EN.md">English</a>
    <p>
</h4>
</div>

# ç›®å½•

- [ä»‹ç»](#ä»‹ç»)
- [Benchmarkç»“æœ](#Benchmark-ç»“æœ)
- [æ¨¡å‹ç»†èŠ‚](#æ¨¡å‹ç»†èŠ‚)
- [æ¨ç†å’Œéƒ¨ç½²](#æ¨ç†å’Œéƒ¨ç½²)
- [åº”ç”¨æ¡ˆä¾‹](#åº”ç”¨æ¡ˆä¾‹)
- [å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒ](#å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒ)
- [å†å² checkpoint](#å†å²-checkpoint)
- [ç¤¾åŒºæ”¯æŒ](#ç¤¾åŒºæ”¯æŒ)
- [å£°æ˜](#å£°æ˜)
- [åè®®](#åè®®)

# ä»‹ç»

Baichuan2 æ˜¯ç”±ç™¾å·æ™ºèƒ½ç»§ Baichuan-7B å’Œ Baichuan-13B ä¹‹ååšå‡ºçš„æ›´æ–°ç‰ˆæœ¬ï¼Œé‡‡ç”¨ 2.6 ä¸‡äº¿  Tokens çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒï¼Œåœ¨æƒå¨çš„ä¸­æ–‡å’Œè‹±æ–‡ benchmark ä¸Šå‡å–å¾—åŒå°ºå¯¸æœ€å¥½çš„æ•ˆæœã€‚æœ¬æ¬¡å‘å¸ƒåŒ…å«æœ‰ 7Bã€13B çš„ Base å’Œ Chat ç‰ˆæœ¬ï¼Œå¹¶æä¾›äº† Chat ç‰ˆæœ¬çš„ 4bits é‡åŒ–ï¼Œæ‰€æœ‰ç‰ˆæœ¬ä¸ä»…å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œå¼€å‘è€…ä¹Ÿä»…éœ€é‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹å•†ç”¨è®¸å¯åï¼Œå³å¯ä»¥å…è´¹å•†ç”¨ã€‚å…·ä½“å‘å¸ƒç‰ˆæœ¬å’Œä¸‹è½½è§ä¸‹è¡¨ï¼š
|         | åŸºåº§æ¨¡å‹  | å¯¹é½æ¨¡å‹ | å¯¹é½æ¨¡å‹ 4bits é‡åŒ– |
|:-------:|:-------:|:-------:|:-----------------:|
| 7B      | [Baichuan2-7B-Base](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base) |[Baichuan2-7B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat) |[Baichuan2-7B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-4bits) |
| 13B     | [Baichuan2-13B-Base](https://huggingface.co/baichuan-inc/Baichuan2-13B-Base) |[Baichuan2-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat) |[Baichuan2-13B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat-4bits) |


# Benchmark ç»“æœ
# Benchmarkç»“æœ

æˆ‘ä»¬åœ¨é€šç”¨ã€æ³•å¾‹ã€åŒ»ç–—ã€æ•°å­¦ã€ä»£ç å’Œå¤šè¯­è¨€ç¿»è¯‘å…­ä¸ªé¢†åŸŸçš„ä¸­è‹±æ–‡æƒå¨æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ã€‚


## é€šç”¨é¢†åŸŸ
åœ¨é€šç”¨é¢†åŸŸæˆ‘ä»¬åœ¨ä»¥ä¸‹æ•°æ®é›†ä¸Šè¿›è¡Œäº†5-shotæµ‹è¯•ã€‚
- [C-Eval](https://cevalbenchmark.com/index.html#home) æ˜¯ä¸€ä¸ªå…¨é¢çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº† 52 ä¸ªå­¦ç§‘å’Œå››ä¸ªéš¾åº¦çš„çº§åˆ«ã€‚æˆ‘ä»¬ä½¿ç”¨è¯¥æ•°æ®é›†çš„ dev é›†ä½œä¸º few-shot çš„æ¥æºï¼Œåœ¨ test é›†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚æˆ‘ä»¬é‡‡ç”¨äº†[Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B/tree/main)çš„è¯„æµ‹æ–¹æ¡ˆï¼›
- [MMLU](https://arxiv.org/abs/2009.03300) æ˜¯åŒ…å« 57 ä¸ªä»»åŠ¡çš„è‹±æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†åˆç­‰æ•°å­¦ã€ç¾å›½å†å²ã€è®¡ç®—æœºç§‘å­¦ã€æ³•å¾‹ç­‰ï¼Œéš¾åº¦è¦†ç›–é«˜ä¸­æ°´å¹³åˆ°ä¸“å®¶æ°´å¹³ï¼Œæ˜¯ç›®å‰ä¸»æµçš„LLMè¯„æµ‹æ•°æ®é›†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†[å¼€æº](https://github.com/hendrycks/test)çš„è¯„æµ‹æ–¹æ¡ˆï¼›
- [CMMLU](https://github.com/haonan-li/CMMLU) æ˜¯ä¸€ä¸ªåŒ…å« 67 ä¸ªä¸»é¢˜çš„ç»¼åˆæ€§æ€§ä¸­æ–‡è¯„ä¼°åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬é‡‡ç”¨äº†å…¶[å®˜æ–¹](https://github.com/haonan-li/CMMLU)çš„è¯„æµ‹æ–¹æ¡ˆï¼›
- [Gaokao](https://github.com/OpenLMLab/GAOKAO-Bench) æ˜¯ä¸€ä¸ªä»¥ä¸­å›½é«˜è€ƒé¢˜ä½œä¸ºè¯„æµ‹å¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ•°æ®é›†ï¼Œç”¨ä»¥è¯„ä¼°æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶è¿›è¡Œäº†éšæœºåˆ’åˆ†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸C-Evalç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆï¼›
- [AGIEval](https://github.com/microsoft/AGIEval) æ—¨åœ¨è¯„ä¼°æ¨¡å‹çš„è®¤çŸ¥å’Œè§£å†³é—®é¢˜ç›¸å…³çš„ä»»åŠ¡ä¸­çš„ä¸€èˆ¬èƒ½åŠ›ã€‚ æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å››é€‰ä¸€å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶è¿›è¡Œäº†éšæœºåˆ’åˆ†ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸C-Evalç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- [BBH](https://huggingface.co/datasets/lukaemon/bbh) æ˜¯ä¸€ä¸ªæŒ‘æˆ˜æ€§ä»»åŠ¡ Big-Bench çš„å­ã€‚Big-Bench ç›®å‰åŒ…æ‹¬ 204 é¡¹ä»»åŠ¡ã€‚ä»»åŠ¡ä¸»é¢˜æ¶‰åŠè¯­è¨€å­¦ã€å„¿ç«¥å‘å±•ã€æ•°å­¦ã€å¸¸è¯†æ¨ç†ã€ç”Ÿç‰©å­¦ã€ç‰©ç†å­¦ã€ç¤¾ä¼šåè§ã€è½¯ä»¶å¼€å‘ç­‰æ–¹é¢ã€‚BBH æ˜¯ä» 204 é¡¹ Big-Bench è¯„æµ‹åŸºå‡†ä»»åŠ¡ä¸­å¤§æ¨¡å‹è¡¨ç°ä¸å¥½çš„ 23 é¡¹ä»»åŠ¡å•ç‹¬æ‹¿å‡ºæ¥å½¢æˆçš„è¯„æµ‹åŸºå‡†ã€‚


### 7Bæ¨¡å‹ç»“æœ
|               | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:---------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|               |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
| **GPT-4**             | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | -       |
| **GPT-3.5 Turbo**     | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | -   |
| **LLaMA-7B**          | 27.10      | 35.10    | 26.75     | 27.81      | 28.17       | 32.38   |
| **LLaMA2-7B**         | 28.90      | 45.73    | 31.38     | 25.97      | 26.53       | 39.16   |
| **MPT-7B**            | 27.15      | 27.93    | 26.00     | 26.54      | 24.83       | -       |
| **Falcon-7B**         | 24.23      | 26.03    | 25.66     | 24.24      | 24.10       | -       |
| **ChatGLM2-6B**       | 50.20      | 45.90    | 49.00     | 49.44      | 45.28       | 31.65   |
| **Baichuan-7B**       | 42.80      | 42.30    | 44.02     | 36.34      | 34.44       | 32.48   |
| **Baichuan2-7B-Base**      | 54.00      | 54.16    | 57.07     | 47.47      | 42.73       | 41.56   |



### 13Bæ¨¡å‹ç»“æœ
|                     | **C-Eval** | **MMLU** | **CMMLU** | **Gaokao** | **AGIEval** | **BBH** |
|:---------------------------:|:----------:|:--------:|:---------:|:----------:|:-----------:|:-------:|
|                     |  5-shot    |  5-shot  |  5-shot   | 5-shot     | 5-shot      | 3-shot  |
| **GPT-4**                   | 68.40      | 83.93    | 70.33     | 66.15      | 63.27       | -       |
| **GPT-3.5 Turbo**           | 51.10      | 68.54    | 54.06     | 47.07      | 46.13       | -   |
| **LLaMA-13B**               | 28.50      | 46.30    | 31.15     | 28.23      | 28.22       | 37.89   |
| **LLaMA2-13B**              | 35.80      | 55.09    | 37.99     | 30.83      | 32.29       | 46.98   |
| **Vicuna-13B**              | 32.80      | 52.00    | 36.28     | 30.11      | 31.55       | 43.04   |
| **Chinese-Alpaca-Plus-13B** | 38.80      | 43.90    | 33.43     | 34.78      | 35.46       | 28.94   |
| **XVERSE-13B**              | 53.70      | 55.21    | 58.44     | 44.69      | 42.54       | 38.28   |
| **Baichuan-13B-Base**       | 52.40      | 51.60    | 55.30     | 49.69      | 43.20       | 43.01   |
| **Baichuan2-13B-Base**           | 58.10      | 59.17    | 61.97     | 54.33      | 48.17       | 48.78   |


## æ³•å¾‹ã€åŒ»ç–—
æ³•å¾‹é¢†åŸŸæˆ‘ä»¬ä½¿ç”¨äº† [JEC-QA](https://jecqa.thunlp.org/) æ•°æ®é›†ã€‚JEC-QA æ•°æ®é›†æ¥æºäºä¸­å›½å›½å®¶å¸æ³•è€ƒè¯•ã€‚æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é€‰é¢˜ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚

åŒ»ç–—é¢†åŸŸåˆ™ä½¿ç”¨é€šç”¨é¢†åŸŸæ•°æ®é›†ï¼ˆC-Evalã€MMLUã€CMMLUï¼‰ä¸­çš„åŒ»å­¦ç›¸å…³å­¦ç§‘ã€[MedQA](https://arxiv.org/abs/2009.13081) å’Œ [MedMCQA](https://medmcqa.github.io/)ã€‚æˆ‘ä»¬é‡‡ç”¨äº†ä¸ C-Eval ç±»ä¼¼çš„è¯„æµ‹æ–¹æ¡ˆã€‚
- MedQA æ•°æ®é›†æ¥æºäºç¾å›½ã€ä¸­å›½å¤§é™†å’Œä¸­å›½å°æ¹¾çš„åŒ»å­¦è€ƒè¯•ã€‚æˆ‘ä»¬æµ‹è¯•äº† [MedQAæ•°æ®é›†](https://huggingface.co/datasets/bigbio/med_qa) ä¸­çš„ USMLE å’Œ MCMLE ä¸¤ä¸ªå­é›†ï¼Œå¹¶é‡‡ç”¨äº†äº”ä¸ªå€™é€‰çš„ç‰ˆæœ¬ï¼›
- MedMCQA æ•°æ®é›†æ¥æºäºå°åº¦åŒ»å­¦é™¢çš„å…¥å­¦è€ƒè¯•ã€‚æˆ‘ä»¬åªä¿ç•™äº†å…¶ä¸­çš„å•é€‰é¢˜ã€‚ç”±äº test é›†æ²¡æœ‰ç­”æ¡ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ dev é›†è¿›è¡Œæµ‹è¯•ï¼›
- é€šç”¨é¢†åŸŸæ•°æ®é›†åŒ…å«çš„åŒ»å­¦ç›¸å…³å­¦ç§‘å¦‚ä¸‹ï¼š
    - C-Eval: clinical_medicine,basic_medicine
    - MMLU: clinical_knowledge,anatomy,college_medicine,college_biology,nutrition,virology,medical_genetics,professional_medicine
    - CMMLU: anatomy,clinical_knowledge,college_medicine,genetics,nutrition,traditional_chinese_medicine,virology 

æˆ‘ä»¬å¯¹ä»¥ä¸Šæ•°æ®é›†è¿›è¡Œäº† 5-shot æµ‹è¯•ã€‚

### 7Bæ¨¡å‹ç»“æœ

|             | **JEC-QA** | **CEval-MMLU-CMMLU** | **MedQA-USMLE** | **MedQA-MCMLE** | **MedMCQA** |
|:---------------------:|:----------:|:--------------------:|:---------------:|:---------------:|:-----------:|
|             | 5-shot     |  5-shot              |  5-shot         |  5-shot         | 5-shot      |
| **GPT-4**             | 59.32      | 77.16                | 80.28           | 74.58           | 72.51       |
| **GPT-3.5 Turbo**     | 42.31      | 61.17                | 53.81           | 52.92           | 56.25       |
| **LLaMA-7B**          | 27.45      | 33.34                | 24.12           | 21.72           | 27.45       |
| **LLaMA2-7B**         | 29.20      | 36.75                | 27.49           | 24.78           | 37.93       |
| **MPT-7B**            | 27.45      | 26.67                | 16.97           | 19.79           | 31.96       |
| **Falcon-7B**         | 23.66      | 25.33                | 21.29           | 18.07           | 33.88       |
| **ChatGLM2-6B**       | 40.76      | 44.54                | 26.24           | 45.53           | 30.22       |
| **Baichuan-7B**       | 34.64      | 42.37                | 27.42           | 39.46           | 31.39       |
| **Baichuan2-7B-Base** | 44.46      | 56.39                | 32.68           | 54.93           | 41.73       |


### 13Bæ¨¡å‹ç»“æœ


|                  | **JEC-QA** | **CEval-MMLU-CMMLU** | **MedQA-USMLE** | **MedQA-MCMLE** | **MedMCQA** |
|:---------------------------:|:----------:|:--------------------:|:---------------:|:---------------:|:-----------:|
|                   | 5-shot     |  5-shot              |  5-shot         |  5-shot         | 5-shot      |
| **GPT-4**                   | 59.32      | 77.16                | 80.28           | 74.58           | 72.51       |
| **GPT-3.5 Turbo**           | 42.31      | 61.17                | 53.81           | 52.92           | 56.25       |
| **LLaMA-13B**               | 27.54      | 35.14                | 28.83           | 23.38           | 39.52       |
| **LLaMA2-13B**              | 34.08      | 47.42                | 35.04           | 29.74           | 42.12       |
| **Vicuna-13B**              | 28.38      | 40.99                | 34.80           | 27.67           | 40.66       |
| **Chinese-Alpaca-Plus-13B** | 35.32      | 46.31                | 27.49           | 32.66           | 35.87       |
| **XVERSE-13B**              | 46.42      | 58.08                | 32.99           | 58.76           | 41.34       |
| **Baichuan-13B-Base**       | 41.34      | 51.77                | 29.07           | 43.67           | 39.60       |
| **Baichuan2-13B-Base**      | 47.40      | 59.33                | 40.38           | 61.62           | 42.86       |



## æ•°å­¦ã€ä»£ç 
æ•°å­¦é¢†åŸŸæˆ‘ä»¬ä½¿ç”¨ [OpenCompass](https://opencompass.org.cn/) è¯„ä¼°æ¡†æ¶ï¼Œå¯¹ [GSM8K](https://huggingface.co/datasets/gsm8k) å’Œ [MATH](https://huggingface.co/datasets/competition_math) æ•°æ®é›†è¿›è¡Œäº† 4-shot æµ‹è¯•ã€‚

- GSM8K æ˜¯ç”± OpenAI å‘å¸ƒçš„ä¸€ä¸ªç”± 8.5K é«˜è´¨é‡çš„è¯­è¨€å¤šæ ·åŒ–çš„å°å­¦æ•°å­¦åº”ç”¨é¢˜ç»„æˆçš„æ•°æ®é›†ï¼Œè¦æ±‚æ ¹æ®ç»™å®šçš„åœºæ™¯å’Œä¸¤ä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œé€‰æ‹©æœ€åˆç†çš„æ–¹æ¡ˆã€‚
- MATHæ•°æ®é›†åŒ…å« 12,500 ä¸ªæ•°å­¦é—®é¢˜ï¼ˆå…¶ä¸­ 7500 ä¸ªå±äºè®­ç»ƒé›†ï¼Œ5000 ä¸ªå±äºæµ‹è¯•é›†ï¼‰ï¼Œè¿™äº›é—®é¢˜æ”¶é›†è‡ª AMC 10ã€AMC 12ã€AIME ç­‰æ•°å­¦ç«èµ›ã€‚

ä»£ç é¢†åŸŸåˆ™é‡‡ç”¨äº† [HumanEval](https://huggingface.co/datasets/openai_humaneval) å’Œ [MBPP](https://huggingface.co/datasets/mbpp) æ•°æ®é›†ã€‚æˆ‘ä»¬ä½¿ç”¨ OpenCompassï¼Œå¯¹ HumanEval è¿›è¡Œäº† 0-shot æµ‹è¯•ï¼ŒMBPP æ•°æ®é›†è¿›è¡Œäº† 3-shot æµ‹è¯•ã€‚
- HumanEval ä¸­çš„ç¼–ç¨‹ä»»åŠ¡åŒ…æ‹¬æ¨¡å‹è¯­è¨€ç†è§£ã€æ¨ç†ã€ç®—æ³•å’Œç®€å•æ•°å­¦ï¼Œä»¥è¯„ä¼°æ¨¡å‹åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå¹¶è¡¡é‡æ¨¡å‹çš„é—®é¢˜è§£å†³èƒ½åŠ›ã€‚
- MBPP åŒ…æ‹¬ 974 ä¸ª Python çŸ­å‡½æ•°ã€ç¨‹åºçš„æ–‡å­—æè¿°ä»¥åŠç”¨äºæ£€æŸ¥åŠŸèƒ½æ­£ç¡®æ€§çš„æµ‹è¯•ç”¨ä¾‹çš„æ•°æ®é›†ã€‚


### 7Bæ¨¡å‹ç»“æœ
|               | **GSM8K** | **MATH** | **HumanEval** | **MBPP** |
|:---------------------:|:---------:|:--------:|:-------------:|:--------:|
|               |  4-shot   | 4-shot   |  0-shot       |  3-shot  |
| **GPT-4**             |   89.99   | 40.20    | 57.32         |  63.60   |
| **GPT-3.5 Turbo**     |   57.77   | 13.96    | 52.44         |  61.40   |
| **LLaMA-7B**          |   9.78    | 3.02     | 11.59         |  14.00   |
| **LLaMA2-7B**         |   16.22   | 3.24     | 12.80         |  14.80   |
| **MPT-7B**            |   8.64    | 2.90     | 14.02         |  23.40   |
| **Falcon-7B**         |   5.46    | 1.68     | -             |  10.20   |
| **ChatGLM2-6B**       |   28.89   | 6.40     | 9.15          |   9.00   |
| **Baichuan-7B**       |   9.17    | 2.54     | 9.20          |   6.60   |
| **Baichuan2-7B-Base**      |   24.49   | 5.58     | 18.29         |  24.20   |

### 13Bæ¨¡å‹ç»“æœ

|                     | **GSM8K** | **MATH** | **HumanEval** | **MBPP** |
|:---------------------------:|:---------:|:--------:|:-------------:|:--------:|
|                     |  4-shot   | 4-shot   |  0-shot       |  3-shot  |
| **GPT-4**                   |   89.99   | 40.20    | 57.32         |  63.60   |
| **GPT-3.5 Turbo**           |   57.77   | 13.96    | 52.44         |  61.40   |
| **LLaMA-13B**               |   20.55   | 3.68     | 15.24         |  21.40   |
| **LLaMA2-13B**              |   28.89   | 4.96     | 15.24         |  27.00   |
| **Vicuna-13B**              |   28.13   | 4.36     | 16.46         |  15.00   |
| **Chinese-Alpaca-Plus-13B** |   11.98   | 2.50     | 16.46         |  20.00   |
| **XVERSE-13B**              |   18.20   | 2.18     | 15.85         |  16.80   |
| **Baichuan-13B-Base**       |   26.76   | 4.84     | 11.59         |  22.80   |
| **Baichuan2-13B-Base**           |   52.77   | 10.08    | 17.07         |  30.20   |


## å¤šè¯­è¨€
æˆ‘ä»¬é‡‡ç”¨äº† [Flores-101](https://huggingface.co/datasets/facebook/flores) æ•°æ®é›†æ¥è¯„ä¼°æ¨¡å‹çš„å¤šè¯­è¨€èƒ½åŠ›ã€‚Flores-101 æ¶µç›–äº†ä¸–ç•Œå„åœ°çš„101ç§è¯­è¨€ã€‚å®ƒçš„æ•°æ®æ¥æºäºæ–°é—»ã€æ—…æ¸¸æŒ‡å—å’Œä¹¦ç±ç­‰å¤šä¸ªä¸åŒé¢†åŸŸã€‚æˆ‘ä»¬é€‰æ‹©äº†è”åˆå›½å®˜æ–¹è¯­è¨€ï¼ˆé˜¿æ‹‰ä¼¯æ–‡ã€ä¸­æ–‡ã€è‹±æ–‡ã€æ³•æ–‡ã€ä¿„æ–‡å’Œè¥¿ç­ç‰™æ–‡ï¼‰ä»¥åŠå¾·æ–‡å’Œæ—¥æ–‡ä½œä¸ºæµ‹è¯•è¯­ç§ã€‚æˆ‘ä»¬ä½¿ç”¨ OpenCompass å¯¹ Flores-101 ä¸­çš„ä¸­-è‹±ã€ä¸­-æ³•ã€ä¸­-è¥¿ç­ç‰™ã€ä¸­-é˜¿æ‹‰ä¼¯ã€ä¸­-ä¿„ã€ä¸­-æ—¥ã€ä¸­-å¾·ç­‰ä¸ƒä¸ªå­ä»»åŠ¡åˆ†åˆ«è¿›è¡Œäº† 8-shot æµ‹è¯•ã€‚

### 7Bæ¨¡å‹ç»“æœ

|               | **ä¸­-è‹±** | **ä¸­-æ³•** | **ä¸­-è¥¿ç­ç‰™** | **ä¸­-é˜¿æ‹‰ä¼¯** | **ä¸­-ä¿„** | **ä¸­-æ—¥** | **ä¸­-å¾·** |
|:---------------------:|:-------:|:-------:|:---------:|:---------:|:-------:|:-------:|:-------:|
| **GPT-4**             | 29.94   | 29.56   | 20.01     | 10.76     | 18.62   | 13.26   | 20.83   |
| **GPT-3.5 Turbo**     | 27.67   | 26.15   | 19.58     | 10.73     | 17.45   | 1.82    | 19.70   |
| **LLaMA-7B**          | 17.27   | 12.02   | 9.54      | 0.00      | 4.47    | 1.41    | 8.73    |
| **LLaMA2-7B**         | 25.76   | 15.14   | 11.92     | 0.79      | 4.99    | 2.20    | 10.15   |
| **MPT-7B**            | 20.77   | 9.53    | 8.96      | 0.10      | 3.54    | 2.91    | 6.54    |
| **Falcon-7B**         | 22.13   | 15.67   | 9.28      | 0.11      | 1.35    | 0.41    | 6.41    |
| **ChatGLM2-6B**       | 22.28   | 9.42    | 7.77      | 0.64      | 1.78    | 0.26    | 4.61    |
| **Baichuan-7B**       | 25.07   | 16.51   | 12.72     | 0.41      | 6.66    | 2.24    | 9.86    |
| **Baichuan2-7B-Base**      | 27.27   | 20.87   | 16.17     | 1.39      | 11.21   | 3.11    | 12.76   |


### 13Bæ¨¡å‹ç»“æœ

|                             | **ä¸­-è‹±** | **ä¸­-æ³•** | **ä¸­-è¥¿ç­ç‰™** | **ä¸­-é˜¿æ‹‰ä¼¯** | **ä¸­-ä¿„** | **ä¸­-æ—¥** | **ä¸­-å¾·** |
|:---------------------------:|:-------:|:-------:|:---------:|:---------:|:-------:|:-------:|:-------:|
|          **GPT-4**          | 29.94   | 29.56   | 20.01     | 10.76     | 18.62   | 13.26   | 20.83   |
|      **GPT-3.5 Turbo**      | 27.67   | 26.15   | 19.58     | 10.73     | 17.45   | 1.82    | 19.70   |
|        **LLaMA-13B**        | 21.75   | 16.16   | 13.29     | 0.58      | 7.61    | 0.41    | 10.66   |
|       **LLaMA2-13B**        | 25.44   | 19.25   | 17.49     | 1.38      | 10.34   | 0.13    | 11.13   |
|       **Vicuna-13B**        | 22.63   | 18.04   | 14.67     | 0.70      | 9.27    | 3.59    | 10.25   |
| **Chinese-Alpaca-Plus-13B** | 22.53   | 13.82   | 11.29     | 0.28      | 1.52    | 0.31    | 8.13    |
|       **XVERSE-13B**        | 29.26   | 24.03   | 16.67     | 2.78      | 11.61   | 3.08    | 14.26   |
|    **Baichuan-13B-Base**    | 30.24   | 20.90   | 15.92     | 0.98      | 9.65    | 2.64    | 12.00   |
|      **Baichuan2-13B-Base**      | 30.61   | 22.11   | 17.27     | 2.39      | 14.17   | 11.58   | 14.53   |


# æ¨ç†å’Œéƒ¨ç½²

æ¨ç†æ‰€éœ€çš„æ¨¡å‹æƒé‡ã€æºç ã€é…ç½®å·²å‘å¸ƒåœ¨ Hugging Faceï¼Œä¸‹è½½é“¾æ¥è§æœ¬æ–‡æ¡£æœ€å¼€å§‹çš„è¡¨æ ¼ã€‚ä¸‹é¢ä»¥ Baichuan2-13B-Chat ä¸ºä¾‹ç¤ºèŒƒå¤šç§æ¨ç†æ–¹å¼ã€‚ç¨‹åºä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½æ‰€éœ€èµ„æºã€‚

æ¨ç†å‰è¯·å®‰è£…ä¾èµ–ï¼š
```shell
pip install -r requirements.txt
```

## Pythonä»£ç æ–¹å¼

```python
>>> import torch
>>> from transformers import AutoModelForCausalLM, AutoTokenizer
>>> from transformers.generation.utils import GenerationConfig
>>> tokenizer = AutoTokenizer.from_pretrained("baichuan-inc/Baichuan2-13B-Chat", use_fast=False, trust_remote_code=True)
>>> model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-13B-Chat", device_map="auto", torch_dtype=torch.float16, trust_remote_code=True)
>>> model.generation_config = GenerationConfig.from_pretrained("baichuan-inc/Baichuan2-13B-Chat")
>>> messages = []
>>> messages.append({"role": "user", "content": "ä¸–ç•Œä¸Šç¬¬äºŒé«˜çš„å±±å³°æ˜¯å“ªåº§"})
>>> response = model.chat(tokenizer, messages)
>>> print(response)
TODO æ”¹ä¸€ä¸ªæ–°çš„case
```

> åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œæ¨¡å‹åŠ è½½æŒ‡å®š `device_map='auto'`ï¼Œä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨æ˜¾å¡ã€‚å¦‚éœ€æŒ‡å®šä½¿ç”¨çš„è®¾å¤‡ï¼Œå¯ä»¥ä½¿ç”¨ç±»ä¼¼ `export CUDA_VISIBLE_DEVICES=0,1`ï¼ˆä½¿ç”¨äº†0ã€1å·æ˜¾å¡ï¼‰çš„æ–¹å¼æ§åˆ¶ã€‚


## å‘½ä»¤è¡Œå·¥å…·æ–¹å¼

```shell
python cli_demo.py
```

## ç½‘é¡µ demo æ–¹å¼

ä¾é streamlitè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä¼šåœ¨æœ¬åœ°å¯åŠ¨ä¸€ä¸ª web æœåŠ¡ï¼ŒæŠŠæ§åˆ¶å°ç»™å‡ºçš„åœ°å€æ”¾å…¥æµè§ˆå™¨å³å¯è®¿é—®ã€‚

```shell
streamlit run web_demo.py
```

## Baichuan-13B-Chat ç¤ºä¾‹è¾“å‡º

<details><summary><b>ä»£ç ä¹¦å†™</b></summary>

```
Userï¼šå†™pythonä»£ç ï¼Œæ‰¾åˆ°ä¸‹åˆ—æ•°ç»„çš„ä¸­ä½æ•°[3.1,6.2,1.3,8.4,10.5,11.6,2.1,5.9]

Baichuan2:
é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°ç»„è¿›è¡Œæ’åºã€‚ç„¶åï¼Œæˆ‘ä»¬æ£€æŸ¥æ•°ç»„çš„å…ƒç´ ä¸ªæ•°æ˜¯å¦ç­‰äºå¥‡æ•°è¿˜æ˜¯å¶æ•°ï¼Œä»¥ç¡®å®šä¸­ä½æ•°çš„è®¡ç®—æ–¹æ³•ã€‚æœ€åï¼Œè¿”å›ä¸­ä½æ•°ã€‚
ä»¥ä¸‹æ˜¯å®ç°è¿™ä¸ªåŠŸèƒ½çš„Pythonä»£ç ï¼š
def find_median(arr):
    arr.sort()
    length = len(arr)

    if length % 2 == 0:
        median1 = arr[length // 2]
        median2 = arr[length // 2 - 1]
        median = (median1 + median2) / 2
    else:
        median = arr[length // 2]
    return median
Example usage:
arr = [3.1, 6.2, 1.3, 8.4, 10.5, 11.6, 2.1, 5.9]
print(find_median(arr))
åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ•°ç»„ [3.1, 6.2, 1.3, 8.4, 10.5, 11.6, 2.1, 5.9] çš„ä¸­ä½æ•°æ˜¯ 6.05ã€‚

```

</details>

<details><summary><b>æ•°å­¦é—®é¢˜</b></summary>
  
```
Userï¼š
é¸¡å’Œå…”åœ¨ä¸€ä¸ªç¬¼å­é‡Œï¼Œå…±æœ‰35ä¸ªå¤´ï¼Œ94åªè„šï¼Œé‚£ä¹ˆé¸¡æœ‰å¤šå°‘åªï¼Œå…”æœ‰å¤šå°‘åªï¼Ÿ

Baichuan2:
æˆ‘ä»¬å¯ä»¥ç”¨ä»£æ•°æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è®¾é¸¡çš„æ•°é‡ä¸ºxï¼Œå…”å­çš„æ•°é‡ä¸ºyã€‚
æ ¹æ®é¢˜æ„æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä»¥ä¸‹ä¸¤ä¸ªæ–¹ç¨‹ï¼š
1. x + y = 35 (å¤´çš„æ€»æ•°)
2. 2x + 4y = 94 (è„šçš„æ€»æ•°)
æˆ‘ä»¬å¯ä»¥å…ˆæ±‚è§£ç¬¬ä¸€ä¸ªæ–¹ç¨‹ï¼Œå¾—åˆ° y = 35 - xã€‚ç„¶åå°†è¿™ä¸ªç»“æœä»£å…¥ç¬¬äºŒä¸ªæ–¹ç¨‹ï¼š
2x + 4(35 - x) = 94
åŒ–ç®€åå¾—åˆ°ï¼š
2x + 140 - 4x = 94
è¿›ä¸€æ­¥æ•´ç†å¾—ï¼š
-2x = -46
æ‰€ä»¥ x = 23ã€‚è¿™æ„å‘³ç€æœ‰23åªé¸¡ã€‚å°† x çš„å€¼ä»£å›ç¬¬ä¸€ä¸ªæ–¹ç¨‹ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
23 + y = 35
è§£å¾—ï¼š
y = 12
æ‰€ä»¥ï¼Œç¬¼å­é‡Œå…±æœ‰23åªé¸¡å’Œ12åªå…”å­ã€‚
```

</details>

<details><summary><b>æŒ‡ä»¤è·Ÿéš</b></summary>

```
Userï¼š
ä»ç°åœ¨å¼€å§‹ï¼Œä½ ä¼šç¿»è¯‘æˆ‘è¯´çš„æ¯ä¸€å¥è¯ï¼Œå¹¶ä¸”ç¿»è¯‘çš„ä¹‹å‰é¢éƒ½å¸¦ä¸Šâ€œtranslateï¼šâ€ï¼Œå‡†å¤‡å¥½äº†å—ï¼Ÿ

Baichuan2:
å¥½çš„ï¼Œæˆ‘å·²ç»å‡†å¤‡å¥½ä¸ºæ‚¨ç¿»è¯‘äº†ã€‚è¯·éšæ—¶å¼€å§‹è¯´è¯ï¼Œæˆ‘ä¼šå°½åŠ›å‡†ç¡®ç¿»è¯‘æ‚¨çš„å†…å®¹ã€‚

Userï¼š
ä½ å¥½

Baichuan2:
Translate: Hello.

Userï¼š
æˆ‘æ˜¯Baichuan2ï¼Œå¾ˆé«˜å…´è®¤è¯†å¤§å®¶

Baichuan2:
Translate: Hi, I am Baichuan2, nice to meet you all.

Userï¼š
å¸Œæœ›é€šè¿‡å¤§å®¶çš„å…±åŒåŠªåŠ›ï¼Œæ—©æ—¥è¿æ¥AGIæ—¶ä»£çš„åˆ°æ¥

Baichuan2:
Translate: I hope through the joint efforts of everyone, we can look forward to the arrival of the AGI era sooner.
```
</details>


## æ¨ç†æ€§èƒ½
Baichuan-13B ä½¿ç”¨äº† ALiBi çº¿æ€§åç½®æŠ€æœ¯ï¼Œç›¸å¯¹äº Rotary Embedding è®¡ç®—é‡æ›´å°ï¼Œå¯¹æ¨ç†æ€§èƒ½æœ‰æ˜¾è‘—æå‡ï¼›ä¸æ ‡å‡†çš„ LLaMA-13B ç›¸æ¯”ï¼Œå¹³å‡æ¨ç†é€Ÿåº¦ (tokens/s) å®æµ‹æå‡ 31.6%ï¼š

| Model       | tokens/s |
|-------------|:--------:|
| LLaMA-13B   | ï¼Ÿï¼Ÿ     |
| Baichuan-13B| ï¼Ÿï¼Ÿ    |

> æµ‹è¯•ç¯å¢ƒå’Œå‚æ•°ï¼šGPU A100-SXM4-80G, PyTorch 2.0.0+cu117, transformers 4.29.1, batch size = 1, ç”Ÿæˆé•¿åº¦ = 2048, ç²¾åº¦ fp16, åŸºäº Baichuan-13B-Base


## é‡åŒ–éƒ¨ç½²

ä¸ºäº†è®©ä¸åŒçš„ç”¨æˆ·ä»¥åŠä¸åŒçš„å¹³å°éƒ½èƒ½è¿è¡ŒBaichuan2æ¨¡å‹ï¼Œæˆ‘ä»¬é’ˆå¯¹Baichuan2æ¨¡å‹åšäº†ç›¸åº”åœ°é‡åŒ–å·¥ä½œ(åŒ…æ‹¬Baichuan2-7B-Chatå’ŒBaichuan2-13B-Chat)ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿé«˜æ•ˆåœ°åœ¨è‡ªå·±çš„å¹³å°éƒ¨ç½²Baichuan2æ¨¡å‹ã€‚

### é‡åŒ–æ–¹æ³•

Baichuan2çš„é‡åŒ–æ–¹æ³•é‡‡ç”¨ç¤¾åŒºä¸»æµçš„é‡åŒ–æ–¹æ³•ï¼š[BitsAndBytesæ–¹æ³•](https://github.com/TimDettmers/bitsandbytes)ã€‚è¯¥æ–¹æ³•å¯ä»¥ä¿è¯é‡åŒ–åçš„æ•ˆæœåŸºæœ¬ä¸æ‰ç‚¹ï¼Œç›®å‰å·²ç»é›†æˆåˆ°transformersåº“é‡Œï¼Œå¹¶åœ¨ç¤¾åŒºå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚BitsAndBytesæ”¯æŒ4bitså’Œ8bitsä¸¤ç§é‡åŒ–ï¼Œå…¶ä¸­4bitsæ”¯æŒFP4å’ŒNF4ä¸¤ç§æ ¼å¼ï¼ŒBaichuan2é€‰ç”¨NF4ä½œä¸º4bité‡åŒ–çš„æ•°æ®ç±»å‹ã€‚  
  
åŸºäºè¯¥é‡åŒ–æ–¹æ³•ï¼ŒBaichuan2æ”¯æŒåœ¨çº¿é‡åŒ–å’Œç¦»çº¿é‡åŒ–ä¸¤ç§æ¨¡å¼ã€‚

### åœ¨çº¿é‡åŒ–

å¯¹äºåœ¨çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ”¯æŒ8bitså’Œ4bitsé‡åŒ–ï¼Œä½¿ç”¨æ–¹å¼å’Œ[Baichuan-13B](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat)æ–¹å¼ç±»ä¼¼ï¼Œåªéœ€è¦å…ˆåŠ è½½æ¨¡å‹åˆ°CPUçš„å†…å­˜é‡Œï¼Œå†è°ƒç”¨ä¸€ä¸ªquantizeæ¥å£é‡åŒ–ï¼Œæœ€åè°ƒç”¨cuda()å‡½æ•°ï¼Œå°†é‡åŒ–åçš„æƒé‡æ‹·è´åˆ°GPUæ˜¾å­˜ä¸­ã€‚å®ç°æ•´ä¸ªæ¨¡å‹åŠ è½½çš„ä»£ç éå¸¸ç®€å•ï¼Œæˆ‘ä»¬ä»¥Baichuan2-7B-Chatä¸ºä¾‹ï¼š  
8bitsåœ¨çº¿é‡åŒ–:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float16, trust_remote_code=True)
model = model.quantize(8).cuda() 
```
4bitsåœ¨çº¿é‡åŒ–:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float16, trust_remote_code=True)
model = model.quantize(4).cuda() 
```
éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç”¨from_pretrainedæ¥å£çš„æ—¶å€™ï¼Œç”¨æˆ·ä¸€èˆ¬ä¼šåŠ ä¸Šdevice_map = "auto"ï¼Œåœ¨ä½¿ç”¨åœ¨çº¿é‡åŒ–æ—¶ï¼Œéœ€è¦å»æ‰è¿™ä¸ªå‚æ•°ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚

### ç¦»çº¿é‡åŒ–
ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·çš„ä½¿ç”¨ï¼Œæˆ‘ä»¬æä¾›äº†ç¦»çº¿é‡åŒ–å¥½çš„4bitsçš„ç‰ˆæœ¬[Baichuan2-7B-Chat-4bits](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat-4bits/tree/main)ï¼Œä¾›ç”¨æˆ·ä¸‹è½½ã€‚
ç”¨æˆ·åŠ è½½Baichuan2-7B-Chat-4bitsæ¨¡å‹å¾ˆç®€å•ï¼Œåªéœ€è¦æ‰§è¡Œ:
```python
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat-4bits", device_map="auto", trust_remote_code=True)
```
å¯¹äº8bitsç¦»çº¿é‡åŒ–ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ç›¸åº”çš„ç‰ˆæœ¬ï¼Œå› ä¸ºHuggingFace transformersåº“æä¾›äº†ç›¸åº”çš„APIæ¥å£ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„å®ç°8bitsé‡åŒ–æ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½ã€‚ç”¨æˆ·å¯ä»¥è‡ªè¡ŒæŒ‰ç…§å¦‚ä¸‹æ–¹å¼å®ç°8bitsçš„æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ï¼š
```python
#æ¨¡å‹ä¿å­˜ï¼Œå…¶ä¸­model_idä¸ºåŸå§‹æ¨¡å‹ç›®å½•ï¼Œquant8_saved_dirä¸º8bitsé‡åŒ–åçš„æ¨¡å‹ä¿å­˜ç›®å½•
model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map="auto", trust_remote_code=True)
model.save_pretrained(quant8_saved_dir)

#æ¨¡å‹åŠ è½½
model = AutoModelForCausalLM.from_pretrained(quant8_saved_dir, device_map="auto", trust_remote_code=True)
```
### é‡åŒ–æ•ˆæœ
é‡åŒ–å‰åæ˜¾å­˜å ç”¨å¯¹æ¯”ï¼š
| Precision   | Baichuan2-7B GPU Mem (GB) |Baichuan2-13B GPU Mem (GB) |
|-------------|:------------:|:------------:|
| bf16 / fp16 | 14.0         | 25.9       |
| 8bits        | 8.0         | 14.2        |
| 4bits        | 5.1          | 8.6        |

é‡åŒ–ååœ¨å„ä¸ª benchmark ä¸Šçš„ç»“æœå’ŒåŸå§‹ç‰ˆæœ¬å¯¹æ¯”å¦‚ä¸‹ï¼š

| Model 5-shot           | C-Eval | MMLU | CMMLU |
|------------------------|:------:|:----:|:-----:|
| Baichuan2-13B-Chat      | 56.74  | 57.32| 59.68  |
| Baichuan2-13B-Chat-4bits | 56.05   | 56.24 | 58.82  |
| Baichuan2-7B-Chat       | 54.35   | 52.93 | 54.99  |
| Baichuan2-7B-Chat-4bits | 53.04   | 51.72 | 52.84  |

å¯ä»¥çœ‹åˆ°ï¼Œ4bitsç›¸å¯¹bfloat16æ‰ç‚¹åœ¨1~2ä¸ªç‚¹å·¦å³ã€‚

## CPUéƒ¨ç½²
Baichuan2æ¨¡å‹æ”¯æŒCPUæ¨ç†ï¼Œä½†éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼ŒCPUçš„æ¨ç†é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ã€‚éœ€æŒ‰å¦‚ä¸‹æ–¹å¼ä¿®æ”¹æ¨¡å‹åŠ è½½çš„æ–¹å¼ï¼š
```python
#ä»¥Baichuan2-7B-Chatä¸ºä¾‹
model = AutoModelForCausalLM.from_pretrained("baichuan-inc/Baichuan2-7B-Chat", torch_dtype=torch.float32, trust_remote_code=True)
```
## Baichuan2 ç›¸å¯¹ Baichuan æ¨ç†è¿ç§»
ç”±äºå¾ˆå¤šç”¨æˆ·åœ¨ Baichuan(Baichuan-7B, Baichuan-13B)ä¸Šåšäº†å¾ˆå¤šä¼˜åŒ–çš„å·¥ä½œï¼Œä¾‹å¦‚ç¼–è¯‘ä¼˜åŒ–ã€é‡åŒ–ç­‰ï¼Œä¸ºäº†å°†è¿™äº›å·¥ä½œé›¶æˆæœ¬åœ°åº”ç”¨äº Baichuan2ï¼Œç”¨æˆ·å¯ä»¥å¯¹ Baichuan2 æ¨¡å‹åšä¸€ä¸ªç¦»çº¿è½¬æ¢ï¼Œè½¬æ¢åå°±å¯ä»¥å½“åš Baichuan æ¨¡å‹æ¥ä½¿ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œç”¨æˆ·åªéœ€è¦åˆ©ç”¨ä»¥ä¸‹è„šæœ¬ç¦»çº¿å¯¹ Baichuan2 æ¨¡å‹çš„æœ€åä¸€å±‚lm_headåšå½’ä¸€åŒ–ï¼Œå¹¶æ›¿æ¢æ‰â€lm_head.weightâ€œå³å¯ã€‚æ›¿æ¢å®Œåï¼Œå°±å¯ä»¥åƒå¯¹ Baichuan æ¨¡å‹ä¸€æ ·å¯¹è½¬æ¢åçš„æ¨¡å‹åšç¼–è¯‘ä¼˜åŒ–ç­‰å·¥ä½œäº†ã€‚
```python
import torch
import os
ori_model_dir = 'your baichuan2 model directory'
# ä¸ºäº†ä¸è¦†ç›–åŸå§‹æ¨¡å‹ï¼Œæœ€å¥½å°†è½¬æ¢åçš„æ¨¡å‹saveåˆ°å¦ä¸€ä¸ªç›®å½•å†æ›¿æ¢
new_model_dir = 'your normalized lm_head weight baichuan2 model directory'
model = torch.load(os.path.join(ori_model_dir, 'pytorch_model.bin'))
lm_head_w = model['lm_head.weight']
lm_head_w = torch.nn.functional.normalize(lm_head_w)
model['lm_head.weight'] = lm_head_w
torch.save(model, os.path.join(new_model_dir, 'pytorch_model.bin'))
```

# åº”ç”¨æ¡ˆä¾‹

# å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒ

## ä¾èµ–å®‰è£…
```shell
git clone https://github.com/baichuan-inc/Baichuan2.git
cd Baichuan2/fine-tune
pip install -r requirements.txt
```
- å¦‚éœ€ä½¿ç”¨ LoRA ç­‰è½»é‡çº§å¾®è°ƒæ–¹æ³•éœ€é¢å¤–å®‰è£… [peft](https://github.com/huggingface/peft)
- å¦‚éœ€ä½¿ç”¨ xFormers è¿›è¡Œè®­ç»ƒåŠ é€Ÿéœ€é¢å¤–å®‰è£… [xFormers](https://github.com/facebookresearch/xformers)

## å•æœºè®­ç»ƒ

ä¸‹é¢æˆ‘ä»¬ç»™ä¸€ä¸ªå¾®è°ƒ Baichuan2-7B-Base çš„å•æœºè®­ç»ƒä¾‹å­ã€‚

è®­ç»ƒæ•°æ®ï¼š`data/belle_chat_ramdon_10k.json`ï¼Œè¯¥æ ·ä¾‹æ•°æ®æ˜¯ä» [multiturn_chat_0.8M](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M) é‡‡æ ·å‡º 1 ä¸‡æ¡ï¼Œå¹¶ä¸”åšäº†æ ¼å¼è½¬æ¢ã€‚ä¸»è¦æ˜¯å±•ç¤ºå¤šè½®æ•°æ®æ€ä¹ˆè®­ç»ƒï¼Œä¸ä¿è¯æ•ˆæœã€‚


```shell
hostfile=""
deepspeed --hostfile=$hostfile fine-tune.py  \
    --report_to "none" \
    --data_path "data/belle_chat_ramdon_10k.json" \
    --model_name_or_path "baichuan-inc/Baichuan2-7B-Base" \
    --output_dir "output" \
    --model_max_length 512 \
    --num_train_epochs 4 \
    --per_device_train_batch_size 16 \
    --gradient_accumulation_steps 1 \
    --save_strategy epoch \
    --learning_rate 2e-5 \
    --lr_scheduler_type constant \
    --adam_beta1 0.9 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-8 \
    --max_grad_norm 1.0 \
    --weight_decay 1e-4 \
    --warmup_ratio 0.0 \
    --logging_steps 1 \
    --gradient_checkpointing True \
    --deepspeed ds_config.json \
    --bf16 True \
    --tf32 True
```

## å¤šæœºè®­ç»ƒ

å¤šæœºè®­ç»ƒåªéœ€è¦ç»™ä¸€ä¸‹ hostfile ï¼Œå†…å®¹å¦‚ä¸‹ï¼š
```
ip1 slots=8
ip2 slots=8
ip3 slots=8
ip4 slots=8
```
åŒæ—¶åœ¨è®­ç»ƒè„šæœ¬é‡Œé¢æŒ‡å®š hosftfile çš„è·¯å¾„ï¼š
```shell
hostfile="/path/to/hostfile"
deepspeed --hostfile=$hostfile fine-tune.py  \
    --report_to "none" \
    --data_path "data/belle_chat_ramdon_10k.json" \
    --model_name_or_path "baichuan-inc/Baichuan2-7B-Base" \
    --output_dir "output" \
    --model_max_length 512 \
    --num_train_epochs 4 \
    --per_device_train_batch_size 16 \
    --gradient_accumulation_steps 1 \
    --save_strategy epoch \
    --learning_rate 2e-5 \
    --lr_scheduler_type constant \
    --adam_beta1 0.9 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-8 \
    --max_grad_norm 1.0 \
    --weight_decay 1e-4 \
    --warmup_ratio 0.0 \
    --logging_steps 1 \
    --gradient_checkpointing True \
    --deepspeed ds_config.json \
    --bf16 True \
    --tf32 True
```

## è½»é‡åŒ–å¾®è°ƒ

ä»£ç å·²ç»æ”¯æŒè½»é‡åŒ–å¾®è°ƒå¦‚ LoRAï¼Œå¦‚éœ€ä½¿ç”¨ä»…éœ€åœ¨ä¸Šé¢çš„è„šæœ¬ä¸­åŠ å…¥ä»¥ä¸‹å‚æ•°
```shell
--use_lora True
```
LoRA å…·ä½“çš„é…ç½®å¯è§ fine-tune.py è„šæœ¬ã€‚
ä½¿ç”¨ LoRA å¾®è°ƒåå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤åŠ è½½æ¨¡å‹
```python
from peft import AutoPeftModelForCausalLM
model = AutoPeftModelForCausalLM.from_pretrained("output", trust_remote_code=True)
```

# å†å² checkpoint
æˆ‘ä»¬æä¾›äº† Baichuan2-7B-Base æ¨¡å‹çš„ 10 ä¸ªå†å² checkpointï¼ˆ[ä¸‹è½½åœ°å€](http://hugging-face.co/baichuan-inc/Baichuan-7B-Base)ï¼‰ï¼Œä¾›ç ”ç©¶ä½¿ç”¨ã€‚

# ç¤¾åŒºæ”¯æŒ

## åä¸ºæ˜‡è…¾
**æ˜‡è…¾NPUå¾®è°ƒ**ï¼šBaichuan2 æ”¯æŒåŸºäºæ˜‡è…¾ NPU çš„ PyTorch + DeepSpeed æ¨¡å‹å¾®è°ƒï¼Œå¾®è°ƒæ‰€éœ€çš„ modelingã€READMEã€ç¤ºä¾‹è„šæœ¬å·²å‘å¸ƒï¼š[Baichuan2-7B](https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/PyTorch/built-in/foundation/Baichuan2/7B)ã€‚13B æ”¯æŒæ­£åœ¨å¼€å‘ä¸­ã€‚

**æ˜‡è…¾NPUéƒ¨ç½²**ï¼šBaichuan2 æ”¯æŒæ˜‡è…¾ NPU æ¨ç†ï¼Œæ¨ç†æ‰€éœ€çš„ modelingã€READMEã€ç¤ºä¾‹è„šæœ¬å·²å‘å¸ƒï¼š[Baichuan2-7B](https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/ACL_PyTorch/built-in/foundation_models/baichuan2/7b)ã€[Baichuan2-13B](https://gitee.com/ascend/ModelZoo-PyTorch/tree/master/ACL_PyTorch/built-in/foundation_models/baichuan2/13b)ã€‚

**MindFormerså¥—ä»¶**ï¼š[MindFormers](https://gitee.com/mindspore/mindformers) æ˜¯æ„å»ºä¸€ä¸ªåŸºäºæ˜‡æ€æ¡†æ¶(MindSpore)å¤§æ¨¡å‹è®­ç»ƒã€å¾®è°ƒã€è¯„ä¼°ã€æ¨ç†ã€éƒ¨ç½²çš„å…¨æµç¨‹å¼€å‘å¥—ä»¶ï¼Œå½“å‰é›†æˆäº†[Baichuan2](https://gitee.com/mindspore/mindformers/tree/dev/research/baichuan2)ï¼Œæ”¯æŒç”¨æˆ·è¿›è¡Œæ¨¡å‹éƒ¨ç½²ã€å¾®è°ƒè®­ç»ƒå’Œåˆ›æ–°ç ”å‘ã€‚

**å¤§æ¨¡å‹ä½“éªŒå¹³å°**ï¼š[æ˜‡æ€å¤§æ¨¡å‹å¹³å°](https://xihe.mindspore.cn) åŸºäºæ˜‡æ€ MindSpore AI æ¡†æ¶ã€MindFormers å¤§æ¨¡å‹å¼€å‘å¥—ä»¶ä¸æ˜‡è…¾ç¡¬ä»¶ç®—åŠ›ï¼Œå°† [Baichuan2-7B](https://xihe.mindspore.cn/modelzoo/baichuan) å¤§æ¨¡å‹èƒ½åŠ›å¼€æ”¾ç»™å…¬ä¼—ï¼Œæ¬¢è¿å¤§å®¶ä½¿ç”¨ã€‚


# å£°æ˜

æˆ‘ä»¬åœ¨æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å¼€å‘å›¢é˜Ÿå¹¶æœªåŸºäº Baichuan2 æ¨¡å‹å¼€å‘ä»»ä½•åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ iOSã€Androidã€ç½‘é¡µæˆ–ä»»ä½•å…¶ä»–å¹³å°ã€‚æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ä½¿ç”¨è€…ï¼Œä¸è¦åˆ©ç”¨ Baichuan2 æ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿè¦æ±‚ä½¿ç”¨è€…ä¸è¦å°† Baichuan2 æ¨¡å‹ç”¨äºæœªç»é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰çš„ä½¿ç”¨è€…éƒ½èƒ½éµå®ˆè¿™ä¸ªåŸåˆ™ï¼Œç¡®ä¿ç§‘æŠ€çš„å‘å±•èƒ½åœ¨è§„èŒƒå’Œåˆæ³•çš„ç¯å¢ƒä¸‹è¿›è¡Œã€‚

æˆ‘ä»¬å·²ç»å°½æˆ‘ä»¬æ‰€èƒ½ï¼Œæ¥ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬å·²ç»åšå‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œä½†ç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»æœ‰å¯èƒ½å­˜åœ¨ä¸€äº›æ— æ³•é¢„è§çš„é—®é¢˜ã€‚å› æ­¤ï¼Œå¦‚æœç”±äºä½¿ç”¨ Baichuan2 å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

# åè®®
å¯¹æœ¬ä»“åº“æºç çš„ä½¿ç”¨éµå¾ªå¼€æºè®¸å¯åè®® [Apache 2.0](https://github.com/baichuan-inc/Baichuan-13B/blob/main/LICENSE)ã€‚å¯¹ Baichuan2 æ¨¡å‹çš„ç¤¾åŒºä½¿ç”¨è§[ã€ŠBaichuan2 æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®ã€‹](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat/resolve/main/Baichuan2%20%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)ã€‚Baichuan2 æ”¯æŒå•†ç”¨ã€‚å¦‚æœå°† Baichuan2 æ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç”¨é€”ï¼Œè¯·æ‚¨æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è”ç³»è®¸å¯æ–¹ï¼Œä»¥è¿›è¡Œç™»è®°å¹¶å‘è®¸å¯æ–¹ç”³è¯·ä¹¦é¢æˆæƒï¼šè”ç³»é‚®ç®± <opensource@baichuan-inc.com>ã€‚
